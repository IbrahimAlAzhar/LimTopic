,Text
0,"Our transcription guidelines occupy a certain position in the continuum between completely preserving the authenticity of learner handwriting and completely ig-
noring it. This position is motivated by our aim of capturing mainly orthographic features, which comes at the expense of other (e.g. readability, comprehension, and cohesiveness) features of the text.
In the course of this study, we only applied the guidelines to German texts. While we are quite certain that they generalize to other alphabetic languages (especially closely related ones), it cannot be ruled out that we missed some language-specific phenomena. However, these could be mitigated by augmenting the guidelines accordingly. Our guidelines are not directly applicable to other, e.g. logographic, writing systems."
1,"As mentioned in Chapter 2, since data is annotated by the author in person, it may include some human error in labeling. However, this can be resolved through a review of the labels and the publication of an amended version. In addition, the sentence data is obtained from the Universal Dependencies (UD) Japanese-GSD data set, this is just one of eight UD Japanese corpora and other ones could be used to expand the data set. Also, this research treats the single kanji homographs as the target, and the work could undoubtedly be improved by expanding the research to kanji combinations. As discussed in Chapter 1, Japanese is one of the languages that lack word boundaries. Therefore, the first interesting point will be that when a kanji homograph is in a kanji combination or phrase, which kanji homographs will tie together to make a word to create a word boundary with other kanji homographs. Then the second point is how the new kanji combination can affect the pronunciation selection of those kanji homographs.
An anonymous reviewer suggests that we compare against the kanji disambiguation system embedded in MeCab. However, we leave this
comparison for future work.
Finally, due to time constraints, this research extracts n-gram features for the target kanji homographs. There will be other features that help analyze the context to improve the model performance."
2,"As PE remains largely undeciphered, our results can only be evaluated on the small subset of numerals which we have manually disambiguated. As noted in the paper, these may be easier than the rest of the corpus, meaning our evaluation can only give an upper bound on model performance.
We use a feature-based classifier to give interpretable results which can more easily be shared and discussed with non-technical experts in Assyriology. A limitation of this approach is that model performance depends on the choice of input features, and features which are effective can sometimes seem arbitrary. We attempt to justify the features used by our model by explaining in Table 2 which aspects of the script each is intended to capture.
Lastly, PE numerals are just one aspect of a complex and multifarious decipherment problem. Our results alone cannot paint a complete picture of this script, and must be interpreted in relation to results from outside of computer science."
3,"limitations in this work, we transliterate all maltese words in the same manner. given the hybrid nature of maltese, it might be optimal to handle words which do not have an arabic origin in a different way. similarly, we do not treat named-entities any differently. moreover, we assume that the maltese text is written using the standard orthographic rules. in turn, the system might produce spurious transliterations for cases with spelling errors. this issue also exists when the text is in raw form, but may be further exacerbated with transliteration. the character mappings could be expanded to handle dropped maltese diacritics, such as writing c instead of ċ, but there are other cases where silent letters such as gh̄ are dropped altogether, making the problem non-trivial."
4,"limitations our work is focused on just a single case study of language identification of romanized text. as detailed in section 2, distinguishing romanized hindi and urdu is a good candidate for a case study for several reasons, but it would be beneficial to extend this work to other language situations. another limitation was our choice to focus on already existing pre-trained models, rather than directly controlling the training data that is input to each model. this means some of the"
5,"limitations there remains a problem we have yet to address: the abbreviation of loanwords in japanese. japanese often abbreviates multi-word expressions after transliterating them into katakana. for example, スマートホン <su-ma-a-to-ho-n> ‘smart phone’ becomes スマホ <su-ma-ho>. for our method, we manually extended these abbreviated words to their full forms, but automating this process would be preferable due to the prevalence of these words in japanese. however, back- transliterating them presents challenges as they deviate further from their original english forms. we designed our method to specifically focus on back-transliterating of content words, unlike many other studies that focused on the name entities data. this is because the loanwords of content words are prevalent in japanese. however, names are also challenging as they are in other languages. previous studies have suggested that a more sophisticated method may be necessary for backtransliterating names."
6,limitations of this research and directions for future research.
7,"limitations our work focuses on the problem of spelling variation in japanese. the japanese writing system is the most complex of any modern writing system (to find anything of comparable complexity, one would have to go back to cuneiform akkadian or hittite) and presents a unique range of issues that impact speech and language technology, one of which is the spelling variation discussed in this paper. nonetheless, as also noted in section 6, we believe that the approach here should be applicable, perhaps with less dramatic results, to other cases where spelling variation occurs. this may be particularly an issue in lan- guages that do not have a standardized writing system—e.g. colloquial arabic dialects—and where a large amount of spelling variation is often observed. however we have not evaluated the approach on this sort of data. our evaluation system is not open-sourced due to the propriety lexical resources, text normalizer and kana/kanji translators. the text normalizer could probably be replaced with, e.g., the open-source mecab (kudo, 2006) system, though we expect that performance would be degraded. similarly our lexical resources could potentially be replaced with publicly available japanese dictionaries such as jmdict (breen, 2004), but again performance would probably suffer. note in particular that unlike cjki’s japanese orthographic dictionary, jmdict entries have not been carefully curated to indicate which spellings are interchangeable, and which are, rather, words with the same reading but distinct meanings. an informal manual evaluation we performed on potential spelling variant pairs that were extracted from jmdict entries nominally representing the same word sense, revealed that about 92% were valid variant spellings, but that the rest were either wrong, or at least unclear."
8,"limitations proto-elamite is undeciphered, which means that our results on this script cannot be compared to any known ground truth. we attempt to ground our results by situating them relative to current assyriological scholarship instead. writing systems exhibit considerable variation in terms of the number of characters used, the visual complexity of those characters, and the degree to which they represent phonetic information. although we try to cover a range of alphabetic and non-alphabetic scripts in our evaluations, we cannot cover all possible cases, and focus on those which have some similarity to the proto-elamite script which is the main concern of our work."
9,"limitations the work described here is part of an ongoing project, and our results, while promising, should be viewed as preliminary. we only report results for the writing systems of two languages, which is a major limitation for a study focusing on typology and cross-writing system variation; past studies in this vein (e.g., marjou (2019); sproat and gutkin (2021); rosati (2022)) have rightly considered a wider range of languages. while the systems we consider (including their “phonographized” versions) provide good points of comparison, the results would be strengthened by considering a wider range of writing systems (which the authors intend to do). finally, it should be noted that the morphological parsing done on the data used in this study may be imperfect, despite the first author’s best efforts. limitations in modern understanding of sumerian result in some cases that should perhaps be viewed with some caution. similarly, for japanese, the treatment of all jukugo words as bimorphemic may or may not accurately reflect how such words should be analyzed in modern japanese. it’s also possible that some non-jukugo two-kanji words were accidentally categorized and parsed as if they were jukugo. certain non-jukugo compounds may have also escaped detection. given the in-progress nature of this research, code and (cleaned) datasets have not yet been made publicly available, but it is the authors’ intention that these resources will be released in the future."

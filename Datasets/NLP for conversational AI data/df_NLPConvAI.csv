,Text
0,"Although LLM-EVAL has shown promising results in assessing open-domain conversations, it is crucial to acknowledge its limitations.
Firstly, the performance of our method relies heavily on the large language models underlying it, which may exhibit biases or generate unexpected outputs. If the language model misinterprets the evaluation schema or prompt instructions, it could lead to inaccurate evaluation scores.
Secondly, the choice of LLM significantly influences the evaluation results, as demonstrated in our analysis. While dialogue-optimized LLMs produce better performance, this selection may limit LLM-EVAL’s applicability for particular tasks or dialogue systems.
Thirdly, our approach employs single-number scoring for each evaluation dimension, which may fail to capture the subtleties of human judgments, particularly for subjective aspects like engagement, creativity, or humor.
Lastly, the effectiveness of LLM-EVAL hinges on the quality and clarity of the prompts and evaluation schemas. Creating such prompts and schemas may require domain expertise and knowledge of LLM behavior, posing challenges for non-experts.
To overcome these limitations, future research can focus on exploring alternative prompt designs, refining evaluation schemas, and expanding the method to cover a wider range of evaluation dimensions and dialogue system types."
1,"Although cTBLS enhances LLMs with tabular knowledge to generate grounded responses, certain limitations remain to be addressed.
Firstly, the efficacy of cTBLS is constrained by the total number of knowledge sources employed during the augmentation process. Token length restrictions in the OpenAI API limit the knowledge augmentation to the top three cells of the table. Another limitation is the incapacity of cTBLS to handle queries pertaining to the entire table. Figure 4 demonstrates one such instance in which the state tracker module accurately retrieves three rows of the table corresponding to oil and gas industries, yet the response generation module fails to utilize this information when transforming the retrieved state into a response. Generally, cTBLS encounters difficulties with counting, comparing the values of cells, and other mathematical operations, an issue we aim to address in future research."
2,"The proposed framework has a limitation in terms of the large GPU resources required, as it necessitates double the memory compared to training a CRS alone. Due to this limitation, we have to forego the use of pre-trained language models such as BERT, which could have been beneficial in enhancing language quality, but their extreme memory requirements make it infeasible."
3,"One of the main limitations of our approach is the use of machine translation to create the IESEMPARSE suite. However, we showed that the overall quality of our dataset is comparable to Samanantar, a human-verified translation dataset. Furthermore, previous studies Bapna et al. (2022); Huang (1990); Moon et al. (2020a,b) have shown the effectiveness of quality estimation in referenceless settings. Lastly, we have also extensively evaluated our dataset with the help of 3 human evaluators for each language as described in §3. We can further take help of GPT4 in future to evaluate the translations in a scaled manner (Gilardi et al., 2023).
The second point of discussion focuses on the motivation for preserving logical form slot values in English. We explore the use cases where querying data in English is crucial, and how this approach can enhance models by reducing latency, limiting vocabulary size, and handling system redundancy. While open-source tools currently cannot achieve this, it would be valuable to evaluate the effectiveness of this task by comparing it with the other two discussed approaches. To accomplish this, we suggest using a dialogue manager and scoring the performance of its responses on the three TOP approaches outlined in the paper.
Another potential limitation of our dataset is that it may contain biases and flaws inherited from the original TOP datasets. However, we contend that spoken utterances are generally simpler and more universal than written ones, which mitigates the risk of cultural mismatches in IE-SEMPARSE dataset. Furthermore, our work is confined only to the Indo-Dravidian Language family of Indic languages due to our familiarity with them and the availability of high-quality resources from previous research. Nonetheless, our approach is easily extendable to other languages with effective translation models, enabling broader applications in various languages worldwide. In the future, we plan to improve our datasets by publicly releasing them through initiatives like NLLB or IndicTransV2, and by collaborating with larger organizations to have the test sets human-translated."
4,"limitations the dataset used in this work is in italian and there may be language-specific limitations in the model performance. geppetto is the only candidate for auto-regressive models for the italian language at the time of this research. therefore, its performance may be limited due to the small number of parameters. we were unable to experiment with it5-large model due to computation power limitations."
5,"limitation on the length of input that a model can handle. situational information can typically be obtained from various sources, and often, an excessive amount of information is present. humans can quickly focus on crucial information and discard the rest, otherwise, it would take forever to read, process, and reason over surrounding information. researchers have identified the frame problem (mccarthy and hayes, 1969) that describes the dilemma of a reasoning system in determining which aspects of a situation change and which remain constant after an action. to date, there has been no satisfactory solution to this questions, making the challenge of situated conversation an interesting open challenge. common ground: knowledge about situations is closely related to common ground–the information shared by conversation participants. without common ground, conversation participants would need to convey every parameter of their message, which is extremely inefficient. the importance of common ground is widely recognized, and decades of dialogue research have been devoted to developing systems that can effectively establish common ground with their interlocutors by inferring, presenting, requesting, accepting, and repairing individual beliefs about various information through conversations (traum and allen, 1994; clark, 1996; poesio and rieses, 2010; inter alia). in this paper, we did not delve into the problem of common ground, but the consideration of situations, which is our main proposal, is the first step towards computational modeling of grounding."
6,"limitations firstly, we did not address the fundamental challenge of determining an adequate amount of situational information. it is very difficult, if not impossible, to describe all the situations required to perform rationale reasoning, so we need to give up somewhere, relying on the reasoning capability of nlp systems. secondly, we did not use large-scale data or conduct an extensive search for optimal hyperparameters and prompts (for gpt-3) in our experiments as the primary goal of this study was to raise attentions to potential issues and benefits associated with situational informaiton. the models may have performed better with different configurations. we did not examined the capabilities of larger plms in conducting situated conversations at scale. in our empirical analysis, we opted for gpt-3 due to its transparency about technical details compared with later versions of gpt. finally, while situational information can aid in the development of truthful and creative response generation systems, it does not address well-known issues associated with conversational technologies, such as safety and bias. in fact, poorly chosen situational information may even amplify undesired bias by linking two irelevant concepts together. to mitigate this problem, researchers and developers should exercise caution when collecting data and carefully monitor system output."
7,"limitations as mentioned in table 3, one limitation of the current study is the small scale of the test sets with modern parsers. we encourage future work to emphasize the development and evaluation on these test sets, specifically those which more closely reflect the current sota in text-to-sql (e.g. t5). additionally, though we have shown using an auxiliary schema prediction model greatly improves the performance of a text-to-sql system, the addition of a model for the text-to-sql task is a limitation given the time and training resources required."
8,"limitations our work is limited in the following senses. first, all presented results relied on the ground truth number of intents to initialize the number of clusters for conducting k-means to retrieve prototypes (§3.1) and infer latent intents (§3.4). in practice, however, the ground truth number of intents is unknown and needs to be estimated by examining a subset of utterances. however, our ablations in §5.2 investigated the impact of overestimating the number of ground truth intents by a factor of two, and found that idas’s performance did not degrade much. while we did not explore this for the final k-means to infer latent intents, future work could investigate cluster algorithms that do not require the number of dialogue states as input, e.g., 2https://github.com/maarten-deraedt/idas-inten t-discovery-with-abstract-summarization. dbscan (ester et al., 1996), mean shift (comaniciu and meer, 2002), or affinity propagation (frey and dueck, 2007). second, we generated labels with the gpt3 (175b) text-davinci-003 model, which may be prohibitively expensive and slow to run for very large corpora. in our initial experiments, we tried using smaller-sized models such as text-curie-001, text-babbage-001, and text-ada-001, as well as flan-t5-xl (chung et al., 2022), but found that the generated labels were of lower quality compared to those of text-davinci-003. in future work, it would thus be interesting to further explore how to more effectively exploit such smaller-sized and/or opensource language models."
9,"limitations the main limitation of our proposed method relies on the additional cost of retrieval. even if the size of our character style indexes is small it still adds latency to our overall pipeline as retrieval must occur once per token. we expect that incorporating the recent work of he et al. (2021) on improving the efficiency of nearest neighbor language models should decrease this latency significantly. as in most nlg work, another important limitation is in quality evaluation. we found qualitative evaluations to be too imprecise for appropriate inter-annotator agreement, and the quantitative evaluations that we present in this paper are all proxies that cannot be said to capture character style or fluency in full. another limitation of our work is the exclusion of models that are only accessible by calling or finetuning powerful external language model apis due to the excessive monetary cost involved. it is almost certain that these larger models would outperform the 6b parameter model we use, and this may also change the relative performance of the techniques that we present. while we feel that this constraint is appropriate at this moment in history and that our position as major aaa developer gives us the authority to make such a claim, shifts in third party model availability and pricing could change the landscape. our work deals with data of a singular domain, video game scripts in english, but represents a wide variety of nationalities and ethnicities over the span of a large catalog of games."
10,"limitations are. current directions with promising results include using llms for conversation synthesis (wei et al., 2023; chen et al., 2023), where high-quality multi-party conversations are synthesized through prompting, and the conversations can be grounded in specific characters or personas. such synthesized conversations may also help adapt methods for conversation analysis and response generation to rarer domains that may not be well-represented in natural corpora."

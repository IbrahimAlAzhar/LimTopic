,Text
0,"One of the limitations of our work is that while we are running the MathPrompter multiple times in different ways to increase the accuracy of our results, this does not always guarantee the correctness of the output. Both Algebraic and Pythonic expressions have the potential to produce the incorrect results, even if the prompt outputs match each other. This is the fail case as shown in the last row of Table 2. Increasing the number of prompts will mitigate this issue. We are currently investigating techniques that can address this issue in a more principled manner."
1,"There are two main limitations to this study. First, because of the lack of downstream datasets, we did not evaluate KG-FLIP on other downstream VL tasks in e-commerce (e.g., substitute recommendation). Therefore, the robustness of the KG-FLIP model on other downstream tasks requires further investigation. Second, the experimental results empirically show that the proposed knowledge-guided pre-training objectives are more effective in producing VL representations that capture subtle distinctions between samples than the standard objectives. However, a theoretical analysis of the effectiveness of our knowledge-guidance strategies is lacking.
†https://aws.amazon.com/batch/ ‡https://aws.amazon.com/sagemaker/"
2,"While the xPQA dataset is created to be as close to the real-world scenario as possible, it has two major drawbacks. Firstly, the candidate set in the dataset does not include the full candidates for a given product because annotating all candidates is prohibitively expensive. The subjectivity of product questions and candidates also makes it hard to get ground-truth short-span answers, which prevents a straightforward end-to-end evaluation over the full candidate set. A potential fix is to run human evaluations on the top-1 candidate over the full candidate set from each model, but it’d be costly to do so. A more realistic solution is to have an online evaluation for the best model only, which we leave for future work. Secondly, the answer annotation is based only on a single candidate because handling information from multiple candidates requires careful instructions on conflicting information and summarization skills. This might limit the model in answering complex questions that require inference over multiple candidates. However, we find this case to be very rare in real customer questions. Furthermore, as we do not summarize multiple candidates, the returned answer can be biased toward the opinion of a single customer. Our evaluation also has potential limitations in that (1) We did not extensively evaluate the quality of generated answers with manual annotation. It is known that BLEU scores might not correlate well with human evaluations on generation tasks, and they can be misleading in certain cases; (2) We only compared major types of baseline algorithms and did not explore the effects of leveraging existing larger, more powerful pre-trained language models such as mT0 (Muennighoff et al., 2022) and FlanT5 (Chung et al., 2022). Conclusions might change if we hire annotators to perform more human evaluations or change the model architecture."
3,"Despite the promising results achieved by our approach, some limitations must be acknowledged. First, the use of product graphs as a knowledge source is a double-edged sword. Indeed, while it provides a valuable resource to exploit, the constant evolution of product graphs may create a strong coupling between the algorithm and the knowledge source, thus reducing the method’s robustness over time. Second, our method’s span-based approach makes it computationally expensive, requiring setting a maximum span size to circumvent this issue"
4,"The proposed KOSBI addresses social bias based on Korean culture with the Korean language. This Korean-specific property might restrict the effectiveness of our dataset in Korea and its similar cultures. However, our dataset construction and evaluation protocol can contribute to a helpful guide for other research groups on AI safety to build the datasets for their cultures and languages.
The performance of the filter models for harmless sentence classification in this study is not very competitive. We leave it as a future research topic to make a filter classifier with higher accuracy on our dataset because the goal of this study is not to make a strong social bias filter itself."
5,"An important limitation of our contribution lies in breadth of the experimental validation. We decided to focus our experimentation on the setup where we encountered the issue of redundant datasets: NER for a large-scale conversational assistant. While it is true that our approach does not make any assumption neither about the task nor about the model architecture, and while we also provide a rigorous proof to support the estimated gain in terms of training time, the extent to which our approach remains the best time-accuracy trade-off when other tasks are considered is not explored in this work.
An additional limitation stems from the lack of absolute results on the internal datasets, as the latter can only be disclosed as relative improvements over a baseline due to internal policy. We attempt to mitigate this by reporting full results on an open dataset, but as we mention we have to resort to upsampling given the artificial deduplication that manually curated datasets incur before publishing."
6,"In this section, we discuss some of the limitations of our current model architecture: (1) NonEnglish locales: Currently in our experiments, we have trained and evaluated models only on English datasets. Building models on non-English locales is the direction for future work, (2) Use of pretrained tokenizer: The T5’s tokenizer in our models has been pre-trained on open-domain datasets, and its vocabulary misses out on e-commerce specific terms. For example, the current tokenizer of T5 tokenizes the phrase “skater midi dress” as [“sk”, “a”, “ter”, “mid”, “I”, “dress”]. Here, the meaning of words “skater” and “midi” is not captured in the tokenized text. We believe that we can overcome this limitation by pre-training T5 on e-commerce data which would help tokenizer understanding and tokenizing the e-commerce specific terms more correctly."
7,"This study is based on a single clinical cohort consisted of 1479 patients, which may limit the generalizability of the results to other clinical cohorts. This specific cohort of patients may not be representative enough of the general population, which may inject certain level of bias brought by the dissimilar distributions of gender, age, race, etc. While we envision the generalization capability of the language models is applicable to other clinical prediction tasks, the focus of this work is majorly about prognostic prediction of cancer immunotherapy, and we hereby have not provided solid evidence to prove that the success can also be extended to other relevant trials. Additionally, we have yet only compared a limited set of transformers and language models, and it is possible that other models may perform better on the tasks evaluated in this study. Finally, it is important to note that while the models in this study achieve high accuracy in clinical prediction, the ultimate value of these models in improving patient outcomes will depend on how well they are integrated into clinical decision-making processes and the impact they have on patient care."
8,"The performance of the EvolveMT system is contingent upon the reliability of the COMET-QE model in providing accurate labels for the MT requests. Utilizing the encoder’s embeddings as features necessitates that the COMET-QE model performs effectively on blind MT requests. The batch reranking of MT requests after each learning step may result in a computational bottleneck if the queue size is substantial. To mitigate this issue, an asynchronous re-ranking process could be implemented, whereby the queue is only reorganized once the re-ranking is completed. Additionally, before the re-ranking process, a diverse subset of the queue can be selected based on the XLMRoBERTa embeddings, which reflect the novelty of the requests relative to previously processed MT requests. The source embeddings from the XLMRoBERTa model can be cached in parallel during the batch feature extraction process utilizing GPU capabilities, thus facilitating efficient COMET-QE inference. EvolveMT could also be optimized for cost-effectiveness by incorporating the cost of each MT in the ensemble into the algorithm."
9,"A major limitation of this research work is only item classification, one specific type of NLU tasks, is used in our experiments. To better evaluate our proposed KCL-FNC method, an expanded testing task set will provide more convincing power. In addition, we only used cross-entropy (CE) loss when training models, in both representation and classifier learning stages. It will be interesting to see the compound effect when applying our proposed method together with some advanced loss types, such as LDAM (Cao et al., 2019)."
10,"We acknowledge that there are certain limitations of this framework. First, generation-based models have latency issue due to the autoregressive generation. Thus, we will explore Non-autoregressive and semi-autoregressive methods in a future study. Second, the knowledge is only stored in model parameters which limits the capacity of the model to make the smarter trigger decision through factchecking and generate a valid rewrite. To this end, we intend to consider a retrieval-augmented generation to incorporate external knowledge to improve performance as well as incorporating more contextual (e.g. if the user is listening music) and personalized (e.g. user preference) signals into the model. Moreover, generative models can also pose quality control challenges, such as hallucinations. To mitigate this issue, we will add constrained decoding (Hao et al., 2022) to control hallucinations."
11,"There are a few limitations pertaining to the training data we used. Some of them are listed below.
1. RadLing has been trained on English reports only, and therefore will not work out of the box in a multilingual setting.
2. There is data imbalance with respect to imaging modalities and anatomies covered by our training data. For example, regions like extremities, neck, spine and shoulder are underrepresented in the dataset, and expected understanding of observations related to those regions may be limited.
3. There needs to be a study on the diversity of the patients and radiologist expertise represented in the data, and how it impacts the performance of the model for underrepresented communities.
4. Different radiologists (and radiology departments) have different preferences and styles of writing reports. In addition, clinical referrals sometimes dictate to what extent some details are documented the report e.g. the Clinical statement. There was no study on the consistency, uncertainty or information richness of the report.
Asides from the training data, there may be space and time throughputs of the model which could make them unsuitable for at-the-edge applications with limited bandwidth."
12,"• We use only the transcript as input to the model. This implies the model wouldn’t know that a hold was long unless the customer said “that was a long hold” or something to that effect. The transcript usually contains language indicating the hold is taking place “may i place you on hold?”, “thanks for holding”, etc, but rarely indicates the exact duration of the hold. Similarly, the model doesn’t know the wait time unless the customer complains explicitly about it.
5-w ay
Cl ass
ific ati
on
Bin ary
Ha rd
Lab els
Bin ary
So ft L
ab els
0.64
0.66
0.68
0.70
0.72
0.74
0.76
Cl as
s 1 P
re cis
io n
by using a small model as an initial gating function.
• If a call center doesn’t collect CSAT surveys through our company, their accuracy will be impacted as they won’t be reflected in the training or test set. We ensure customers understand this by training our agents to explain it and including it in help center documentation."
13,"This paper introduces two heuristic approaches to filter noisy feedback data. Although we showed that these simple methods improve the performance of QA models, they have various limitations and they represent only an initial step for future re-
search on real feedback data. The core of the relevance filtering is based on the assumption that correct feedback occur when the model and the user agree on the labels. This approach may introduce a selection bias towards tuples associated with ""simpler"" q/a pairs, which are already well understood by the model and thus potentially ineffective for training. Although the model can easily discard q/a pairs whose feedback are clearly different, the risk is that uncertain pairs close to the classification boundary (i.e., model score close to 0) are penalized and easily filtered as they will receive a reliability score close to 0.
Regarding the collaborative approach, the main limitation concerns the clustering strategy adopted to aggregate questions. On one hand, we want to reduce as much as possible the number of clusters such that we have a sufficiently high amount of feedback per cluster. This makes the proximity computation between users and the voted feedback vector robust.
On the other hand, the clustering may introduce additional noise by aggregating different and nonequivalent questions into the same cluster. This aspect may reduce the reliability of the voted feedback vector.
Finally, as mentioned in the previous sections, feedback data and q/a pairs used in this work come from real users traffic. For this reason, we only described the high-level approach of integrating feedback and we showed the impact on public benchmarks. A harsh limitation is caused by the private nature of the customer data, which cannot be released for public research."
14,"Our work explores a dimension of context understanding by Voice Assistants but it is only a small step. Firstly, we only consider 5 categories, while screens have a myriad of other texts and visual
content. We do not include image context into our reference understanding models. But users could use them when formulating references to texts near them. Using image captions or some pixels would improve coverage. Our system leverages entities extracted by upstream and hence is bounded by the performance of that. Also our model evaluates each entity separately while there may be benefit in considering the entire screen holistically."
15,"Our prescription digitization approach has a few limitations but is still effective for a broad enough application domain and permits future enhancements that address these limitations. First, our system uses an off-the-shelf text extraction tool (AWS Textract) that provides accurate extractions on printed prescriptions but has variable performance on hand written data depending on the legibility of the handwriting. In future, we plan to build a specialized extraction model trained to recognise medical practitioner’s handwriting to replace AWS TextExtract. Further, multiple components in our approach (e.g., attribute extraction) have been trained on primarily English transcriptions. Extension to other language prescriptions requires access to medical vocabulary and training data in those languages. Note that AWS Textract supports multiple languages and can be readily paired with an automated translator to convert the content to English. We did not consider this option since multilingual prescriptions in India tend to have mixed content with medications written in English itself. Lastly, the performance of multiple tasks such as advice block detection, medication attribute extraction and matching-canonicalization depends on the coverage of the available medical catalog."
16,"limitations this study has potential limitations. when the cwseg model is applied to a new domain, we assume that words and phrases solely related to the domain are available."
17,"limitations while we conducted extensive experiments and demonstrated the effectiveness of the suggested approach for controlled bandit learning in the context of the skill routing problem, there are multiple directions of improvement for future studies. we believe one of the limitations of the suggested constrained optimization framework is that it relies on expert-defined conditions on an arbitrary segmentation of samples. it entails the need for human intervention and manual constraint definition/optimization which can be challenging. another limitation we faced was during our experiments which showed additional compute overhead of between 2 to 3 times for different constrained optimization methods due to additional optimization objectives, inner loops, and backward passes."
18,"limitations we identify the following limitations in our work: first, our ftt framework captures and models topic-level temporal patterns for forecasting temporal trends. though the forecasts bring better temporal generalizability, ftt could hardly forecast the emergence of events in new topics. second, ftt considers temporal patterns based on the topic-wise frequency sequences to identify patterns such as decrease, periodicity, and approximate stationery. there might be diverse patterns that could not be reflected by frequency sequences. third, limited by the scarcity of the dataset that satisfies our evaluation requirements (consecutive time periods with a consistent data collection criterion), we only performed the experiments on a chinese text-only dataset. our method should be further examined on datasets of other languages and multi-modal ones."
19,"limitations our proposed approach is designed explicitly for evaluation of task-oriented dialog systems, and is hence unlikely to generalize well to chitchat systems. most traffic to our platform (and our annotation workflows, including dqa) comes in the form of task-oriented interactions. user turns in the traffic we analyze tend to be quite short (usually less than 20 tokens) and direct, so our model is unlikely to perform as well on dialogs driven by long-form user utterances. ethical considerations we do not envision any ethical concerns with the research presented here. no customer data is released or presented in this paper, and even our internal data sources are fully de-identified and contain no customer personal identifiable information (pii)."
20,"limitations in this study, we collected feedback on the usefulness of model responses from customer service agents at ar. these agents were recommended based on their availability and experience with conversation assist; however, we did not receive details about the agents such as their level of training or experience, which may have an impact on their preferences using the suggested responses. furthermore, while agents in our study received a flat rate per judgment with no bonus or penalties to how they judged the response, some businesses have existing agent metrics (e.g. actual handle time, aht targets, etc.) that could incentivize the agents to behave differently while performing their jobs. these metrics have the potential to exert pressure on agents in real-life situations to accept responses at a higher rate than in this study. the linear models in section 4.4.2 are based on the judgments of 5 agents on 3 lmm model outputs for 287 conversations. while they have shown a statistically significant relationship between usage rates and perplexity, this is a small pilot analysis. additional data will be necessary to determine how well this generalizes. our cost savings framework also makes a number of simplifying assumptions about workforce optimization. we’ve noted some of these assumptions in section 3.1, and they should be considered when leveraging this framework for different types of products. in addition, while the explicit goal of these models is to make agents’ jobs easier, we expect from previous work studying vigilance tasks (warm et al., 2008) that there can be an upper bound to how much cost could be saved with an excellent llm, as there would be less benefit from the agent acting as a human in the loop as their vigilance wanes."
21,"limitations the two proposed models (ad fofe and aa fofe mixture) have been tested on more languages than the ones mentioned in this paper, but the comparison with transformer models has not been done for every language. this paper only uses word-level lms. we have done preliminary experiments with subword-level lms but more extensive investigation is needed to draw proper"
22,"limitations and future work in our study, we focused on a high-resource setting with access to approximately 22.5k hours of labeled speech data. while we compared our models with conformer and transformer-based aed and ctc models, we did not include rnnt models due to their higher compute resource requirements. to accommodate deployment constraints, we employed a smaller model with approximately 60 million parameters, which limited its performance. moving forward, our future work aims to explore the potential benefits of leveraging large unsupervised datasets and larger models to further enhance our system and extend its applicability to other indian languages, which typically have less available data compared to hinglish. building upon our previous success in adapting a non-streaming model for end-to-end speech-to-intent detection in customer support voicebots (goyal et al., 2022), we are motivated to investigate the feasibility of developing a single joint model for automatic speech recognition (asr), end-of-speech (eos) detection, and spoken language understanding (slu). additionally, we are keen on exploring the development of multilingual asr models."
23,"limitations to ensure high quality extractions for plate, we optimize our annotation process for precision. for example, for the product link attribute, we generally annotate only one product link per product. in an application scenario, the user would not need multiple links to a purchase page, but this could potentially harm the precision of the evaluated models. in addition, we assume that all attributes are text-based. this has the potential of missing additional product information which could be helpful to users, such as images of the product. in future work, we would like to extend plate by incorporating other modalities."
24,"limitations our work has several limitations. first, our consistency study focuses on our used categorization model and was conducted on only one specific dataset. it might not perfectly generalize to other problems. second, the proposed solutions are based solely on data augmentation without changing the current production settings and model. other approaches such as changing the model’s objective function to take consistency into account might also benefit the solution. lastly, in terms of user perspective, while our solution show significant improvement over the baseline, inconsistencies are still visible."
25,"limitations as mentioned previously, the main limitation of our approach is that, very complex joins e.g. sequences of joins of different types and joining on columns which have different names in different tables is not straightforward in our approach. one extension to possibly handle this would be using a decoder to generate the complex sequence of joins and column relations. note, however that this does not complete revert to the constrained sequence-tosequence decoding as in semantic parsing, as its not for the entire query but only the table joins or the from section of a sql statement. the select, where, order by and group by can still be done via our approach and we could also continue to use mtl. the second limitation of our approach is subquerying capability which currently we do not have a strategy to handle queries which would require them. however, this is notoriously hard even for existing sota semantic parsing algorithms e.g. the current leader on the spider dataset graphix-t5-3b li et al. (2023) achieves only 50 exact match (em) accuracy on the extra hard spider data subset and 61.5 on the hard subset. overall this model has a"
26,"limitations of this study. first, we focus on left-to-right code generation without considering right-side and cross-file context, which can be used to determine broader categories of errors with improved precision. second, each static analysis tool has its own limitations. thus, the presented analysis is limited by pyflakes’s accuracy and coverage to detect certain code issues."
27,"limitations we believe a potential limitation of this work is its reliance of curated samples from historical incidents. due to the complexity of real-world conversational agents, the decision to introduce a new sample to the r/p set requires human expert involvement which could be costly and pose challenges in terms of reliability. another challenge we faced after the deployment of this framework was managing the life-cycle of the collected r/p samples. in a dynamic environment, a regression or progression pattern may lose relevance over time. therefore, we find it challenging to re-actively deal with retirement of such historical samples."
28,"limitations safer framework is designed for handling bert classification label noise without using any clean data. despite the fact that the bert is one of the most extensively used models in the industrial domain, the influence of label noise on gpt models and prompt should be further studied in light of the recent rapid progress. we believe that our framework is compatible with these models, however, further evaluation is required. another limitation is the types of label noise. we analyze safer using synthetic datasets with uniform and flip label noise which are typical classlevel noise in practice. however, in industrial applications, the model may experience instance-level label noise, which is beyond the scope of our investigation. although safer achieves robust results in our biomedical literature mining task under human label noise, we encourage users to examine the label noise type first in their own application."
29,"limitations in this paper we compare a shared encoder architecture for slu to a baseline architecture that was chosen based on the specific latency and cost constraints of an industry slu system. since encoder model sizes were chosen based on specific constraints the results may not be directly comparable to model sizes more commonly used in the literature such as bert-large and bert-base. we expect the general benefit and order of magnitude of accuracy improvements shown in our evaluations to transfer to comparable setups with different parameters. the primary focus of this paper is on accuracy improvements and addressing challenges of realworld slu systems such as distribution drift and feature expansion. we do not elaborate on the details of the computational cost and inference aspects. a detailed analysis of compute cost and benchmarks of cpu and gpu inference would better highlight the infrastructure cost benefits of a shared encoder architecture for slu. regarding the multi-lingual aspect of the encoder we only tested a single grouping of similar european languages (german, french, italian and spanish). a more extensive analysis of different language groups would demonstrate that similar trade-offs seen in other works on multi-lingual language models also apply for the shared encoder architecture."
30,"limitations the study has several clear limitations. firstly, the training and validation datasets used in this study are still relatively small. a larger dataset would give more robust results for comparing different encoders. additionally, the experiments were only conducted on the ability to generalize to unseen entities and not on the ability to generalize to unseen sketch types, which is also of key importance when addressing low resource ckbqa. moreover, the methodology used in this study relies on annotated question-program pairs, which are expensive to collect. learning only from question-answer pairs or even a question with an indicated difficulty based on whether the model was able to answer the question, could be more easier to collect. while the models achieve high accuracy on most of the knowledge base components, overfitting can occur at different stages during training, leading to high accuracy for one component at one training step but poor accuracy for another component at another step. in the future, revising the training procedure or the model setup may help address this issue."
31,"limitations although our badge framework is shown to be effective in improving the multi-exit model training and early exiting, it still has certain limitations that need to be addressed in the future: (a) blockwise bypasses indeed introduce new parameters and additional flops. we would like to explore more parameter-efficient methods to improve multi-exit model training in future works. (b) in this work, we demonstrate our framework’s performance on sentence classification or pair classification tasks. in future works, we would like to extend our work to broader tasks such as sequence labeling, relation extraction, and text generation. we would like to explore this aspect in future work."
32,"limitations building this system was nothing trivial. in our understanding the main challenges where to obtain data access, to chain very specialised artificial intelligence models, and to handle the iterations between the (machine) knowledge model, the customer expertise and the algorithms. we detail each of these challenges herein. access to annotated data piracy and ais spoofing are still too frequent, even though not frequent enough so as to result in the availability of datasets to train and evaluate an automatic system. the proposed approach mainly relies on subtask evaluation (notably on the information extraction steps). the coherence check is fully parameterizable in order to choose a sensibility to all possible variations. a stream of work concerning the automatic/statistic evaluation of the full pipeline is still going-on. hyper-specialized ais most of the substasks here are instantiated by trained modules, which inherently contain an adherence to the ontology used for labelling the training dataset. information extraction from texts were fine-tuned for short pieces of news, and limited to english. this cuts off numerous relevant sources of information, typically from local newspapers anywhere on earth. handling business, ontology and algorithms together the trend to fully automatize screening processes seems intuitive for many data scientists, but is actually not desirable for a security point of view: first, because the targeted elements are “black swans” which occur far too little in the training datasets, and more often than not, do not appear twice. moreover, having too much confidence in the machine is clearly identified as a security risk, among other ai-system biases(rastogi et al., 2020). instead, the desired system should help the operator to handle more data about more incoming ships, and enabling them to focus on what is determining."
33,"limitations similar to other commercial products, embedding apis are subject to changes that could potentially impact their effectiveness, pricing, and usability. thus, it is important to note that our findings are specific to the apis accessed during january and february 2023. nevertheless, we believe our evaluation framework can serve to thoroughly assess future releases of these apis. moreover, we limit our focus to the effectiveness and robustness of semantic embedding apis. nonetheless, safe deployment of retrieval systems for real-world applications necessitates the evaluation of their fairness as well as additional considerations. despite their scale, language models have been found to learn, and sometimes perpetuate societal biases and harmful stereotypes ingrained in the training corpus (bender et al., 2021). consequently, it is crucial to assess potential biases in the embedding apis with respect to protected and marginalized groups. this paper does not delve into this aspect of api evaluation and further research is required to examine these and other issues in real-world applications."
34,"limitations the main limitations of the proposed architecture are related to the presence of the frozen feature extractor. the accuracy of the classification module is proportional to the quality of features. since the ensemble weak learners are single-layer neural networks, the entire feature extraction process relies on a pre-trained model that strongly limits the upper bound of classification accuracy. such approach reduces the method complexity, but also makes it prone to errors when embeddings have low quality. achieving accuracy at a satisfactory level, which is crucial in real world systems, requires the use of high quality feature extractors. currently, plenty of pretrained sota models are available for free in domains such as text or image classification, but if such extractor is not available, does not produce reasonable features or is too expensive to use, our architecture may not be the best choice. another issue is relatively long training time comparing to the reference methods (see a.3). the introduction of a differentiable soft knn layer resulted in additional computational effort that clearly impacted the model complexity. this limits the use in low latency systems with machine learning models trained online."
35,"limitations a first limitation of our contribution stems from the fact that to compute the focal distillation term in the loss, predictions from the old model are required. this additional stream of information will therefore cause a slight increase in the required computational power. in this work, we only experimented with fd based on mean-squared error between pre-softmax logits as that approach yielded best results in the paper our experiments are based on, leaving experiments using fd with kullback-leibler divergence between temperature-scaled softmax outputs for future research. due to inference time limitations in a production setting, we did not investigate the reduction of negative flips with ensembles either. finally, we have not tested more principled approaches for ner distillation and focused on tokenlevel distillation leaving sequence-level distillation for future work."
36,"limitations in this work, we have employed different strategies to identify the important utterances from early cohort. however, since a voice assistant system consists of many components, such as wakeword, automatic speech recognition, nlu, dialogue manager, where errors occurring in one step might result to the final overall incorrect response. we have not discussed or considered the interaction among these components in this study. last but not least, weak signal learning using users’ feedbacks has shown to be beneficial in many studies, it is important to classify and identify the types of feedbacks that are relevant and those that are not relevant to nlu improvement (e.g., a negative feedback might not be caused by an immediate previous request, but be caused by other factors such as unsupported features, asr incorrect recognition, device technical problems)."
37,limitations of our model based on various question types. 5https://console.cloud.google.com/ 6larger batch size leads to out of gpu memory errors. 7https://huggingface.co/distilbert-base-cased
38,"limitations as our models are trained on customer-agent conversations in english, they might not be suitable to be used in other domains, types of inputs (i.e written text), or languages. moreover, as we demonstrated in the paper that the model has limitations in certain question types, the user needs to decide which question types to be used when deploying the system in production. though the dialogled model performs better, it requires higher computing resources. on the contrary, even though the distilbert model consumes lower memory, its performance is poorer than the dialogled model."
39,"limitations in qa dataset. finally, we have tested the model on proprietary ner datasets and radling-kg has yielded 0.92- 0.93 macro f1 on less represented anatomies like neck, while for the highly represented anatomies, f1 is as high as 0.98. this actually shows the potential of using radlex in radiology pretraining. thus, in a real world setting with high imbalances in datasets, radling-kg is more robust. in future we would like to explore more ways to infuse knowledge by (a) using text description of context like (yuan et al., 2021), (b) retrieving context from biomedical knowledge graphs like snomed 4 and umls, and (c) more robust knowledge embedding methods. we would like to experiment with larger datasets and models, and work with more downstream radiology applications. 4https://www.nlm.nih.gov/healthit/snomedct/index.html"
40,"limitations in this work, we develop a unified model framework that is applicable to different ner tasks. through experiments, we show the effectiveness of our method on different ner tasks, both in english and chinese. however, we recognize that our method is not tested on ner tasks where the input sequences are extremely long. in addition, our method is not tested on few-shot scenarios. we will investigate these issues in future work."
41,"limitation of neuspell due to sequence labeling is that it can’t handle compounding errors like iphonepro to iphone pro. it’s evident that our diverse synthetic data generation techniques are effective and lead to significant improvement even with a simple 1 layer enc/dec (reparos-base) transformer compared to deeper pre-trained models like bert and neuspell. adding candidates from our novel phonetic transliteration model was beneficial and led to a total absolute gain of 2-3% at query level consistently across the models and 7.5% accuracy improvement at the word candidate level. effect of curriculum learning: while reparosbase itself is good than the competent baselines, our error analysis showed that it still couldn’t address the complex edit/phonetic + compounding spell errors. this led us to design a few new curricula to improve. our first curriculum reparosbase-1, was to simply add more of complex edit/phonetic+compounding training samples. this resulted in marginal improvement over reparosbase. however, with a different curriculum of only fine-tuning reparos-base on tougher mistakes (model reparos-c1) we observe that the performance increases significantly on the improvement set where most of the mistakes lie, however, there’s a drop in the regression set performance when compared to the reparos-base and reparosbase-1. on analyzing this further, we observed that this was due to the over-correction problem where the model is aggressively altering correct queries in the regression set. hence, we change the curriculum and in reparos-c2 we find that a further fine-tuning on weakly supervised user feedback data improves upon all the variants significantly on both the data sets. this is intuitively due to relatively more frequent queries in the regression set on which receiving implicit user-feedback through clicks is possible at scale. thus adding this new curriculum helped acheive the best performance. online evaluation: in production, we adopt a 2-step architecture by adding an ml ranker (yang, 2022) that does the final candidate selection (from multiple candidates from the reparos/googleswbs). this multi-stage setup empirically produced better results than just finetuning the nmt model since top-10 accuracy of reparos-c2 is 76.31% on improvement set and 98.08% on regression set. this helped all the models (and reparos more due to their better top-k accuracy) and is removed from results"
42,"limitations and future work in this work we did not consider the following aspects, which we discuss below and lay out directions for how to address them in future work. combining reformulation operations: the reformulation operators, except rep, which is applied jointly with other operators, are applied sequentially, in their given order, e.g. roo+gen. this has two potential limitations that we aim to address in future work. first, applying multiple operators sequentially has the negative impact of increased inference latency as the surf model needs to be applied multiple times, which can become a bottleneck for systems that process large traffic volumes. second, by applying sequentially the reformulation operators, the likelihood of cascading errors or the model making mistakes in terms of the target reformulation shape increases. we aim to address this limitation in the future by fine-tuning the model to jointly perform multiple reformulation operators in a single pass. large language models (llm): in this work we relied on bart (lewis et al., 2020) as our seq2seq model, and did not experiment with newer multi-billion parameter llms. recently we have seen rapid progress in the space of llms, both in terms of model size and their capabilities to perform various tasks (chung et al., 2022). however, we note that deploying llms is limited by their high inference latency, particularly in high-traffic, low-latency systems such as ours. furthermore, for experimenting with api-based approaches such as chatgpt and gpt-4, using these systems was not possible due to data confidentiality. while we will explore leveraging llms for this task in the future, current experimental results show that even smaller language models such as bart, with a sufficient amount of training data, can be fine-tuned to perform the task accurately. evaluation on public datasets: our evaluation focused on real-world unanswered user utterances from voice assistants. we did not use public datasets as currently available resources do not accurately represent customer behavior at scale. however, the community is aware of this divergence, and there are initial efforts in different nlp tasks to create public datasets that represent real-world user behavior. for example, in the the task of named entity recognition there has been recent work on bridging the gap between academic datasets and real-world problems by creating new resources that represent contemporary challenges that are encountered in practice (fetahu et al., 2023; malmasi et al., 2022). in future work we will consider evaluating surf on such datasets as they become available. furthermore, the findings from our work may be used to create data that includes the challenges we identified as part of our analysis (either by organically collecting such data, or simulating it to generate synthetic data). multilingual experiments: we only considered english-language questions in this work, and it will be of interest to consider how our approach can be extended to other languages using multilingual models. the evaluation of cross-lingual transfer for this task is another open research area."
43,"limitations and future work one limitation of our approach is that we do not display or rank multiple reformulations. it is possible that a query can be reformulated into multiple possible questions. for example, the query “apple tv bluetooth” can be reformulated into “how do i connect a bluetooth device to my apple tv” or “does apple tv support bluetooth”. in our future work, we aim to explore the integration of multiple reformulations into the faq retrieval process to further enhance the overall user experience. another limitation is that we do not train an end-to-end faq retrieval model. in the future, we plan to train the faq retrieval model using the reformulations so that the original query can directly be used."
44,"limitations the data from the pitt dataset (hussain et al., 2017), while useful for our paper, contains many images and annotations that may perpetuate harmful stereotypes according to sensitive characteristics such as gender and carry the risk of amplification by machine learning models. we plan to collaborate with ai robustness researchers to identify such examples and develop methods for improving ml models in terms of robustness and reliability."
45,"limitation because our architecture only predicts one topic. there are very few cases where we observe that the model learns to put undue emphasis on certain keywords (“back” in topic and question, example 9 in table 5) and gives the highest score to the wrong topic. b taxonomy and tcdl module output"
46,"limitation of the existing medical ner models is their poor performance on nonus and eu prescriptions due to bias in the training data, which is almost exclusively based on useu centric medical content and vocabulary. in our approach, we have deliberately chosen to have explicit dependence on aspects that vary across geographical regions (e.g., medical catalog), which enhances the applicability of our approach. to further limit the model bias and minimize distributional differences between training and production settings, we have trained our models on prescription images that are randomly sampled from customer uploads. these often include low resolution and improperly positioned images. in future, as the scope of deployment changes, we plan to periodically retrain the model with training images by sampling from the production data. health safety: one of the primary concerns in prescription digitisation is the impact of errors on patient health and adherence to health regulations. to alleviate adverse outcomes, we have multiple guardrails. first, we present the top three suggestions along with scores for each medication for two-fold review by customer and pharmacist. second, to avoid prescription abuse (e.g., manipulation of quantities, prescription reuse) and comply with regulations, there are additional checks based on the prescription date, patient purchase history, and recommended limits on medication quantities. usage for a limited scope: our proprietary system has been trained for a specific-use case, i.e., prescription digitization with acceptable performance on primarily english printed prescriptions for india region. we plan to use the model within this limited scope and expand usage only after adequate benchmarking. to limit the risks of misuse, we do not plan to release this system externally."

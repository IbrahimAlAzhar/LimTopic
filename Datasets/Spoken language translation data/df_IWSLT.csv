,Text
0,"While we have done our best to create high-quality evaluation data, there are limitations that should be kept in mind when using these datasets. It is known that creating translations by post-editing may bias data towards the output of the MT systems used for initial translations; however, many transcription and translation vendors now exclusively use postediting rather than translation from scratch and so direct translation may not be an option in all cases. This could influence metrics toward similar MT systems. The presented evaluation sets are moderately sized compared to datasets in other domains with plentiful mined data, and may be best used in conjunction by reporting on both the development and evaluation sets for statistical significance. The evaluation sets also have a necessarily limited set of speakers which may not be fully representative. Systems which tune to the development set run the risk of over-fitting to specific speakers or content. We do not perform a comparison to human evaluation here, but refer interested readers to the IWSLT’23 evaluation campaign findings paper which runs this comparison for a variety of systems with the ACL 60/60 data (Agarwal et al., 2023)."
1,"There are several limitations of this study. First, it is done on one language pair although we believe this should not qualitatively change the results. Second, only one set of standard model sizes was evaluated for AST student and NMT expert; we expect it be in line with reported findings for NMT (Ghorbani et al., 2021). Finally, while alluding to the potential of using large pre-trained ASR models instead of manual transcripts for IL-based AST, our current work must be seen as a proof-of-concept experiment where we train ASR models on a few hundred hours of audio, and discard the manual transcripts in IL training, showing the feasibility of our idea."
2,"The data that we analyzed are limited to only one English-German language pair, 5 SST systems from IWSLT 2022, and three domains. All the systems were trained in the standard supervised fashion on parallel texts. They do not aim to mimic interpretation with shortening, summarization or redundancy reduction, and they do not use document context. The used MT metrics are good for evaluating individual sentence translations and that is an important, but not the only subtask of SST. We assume that some future systems created with a different approach may show divergence of CR and the offline MT metrics.
Furthermore, we used only one example of human interpreting. A precise in-depth study of human interpretations is needed to re-assess the recommendation of translation or interpreting as reference in SST."
3,"The scores reported in the SI test were lower than those in the offline test. Reporting results on other SI data would support seeing the effectiveness of our method. To our knowledge, this is the first work to use SI data as speech translation data. There are no other language pairs SI data than EnglishJapanese pairs those source speech and target text aligned."
4,"Apart from all the advantages that our work achieves, some limitations still exist. Firstly, in this work, we investigate the efficacy of applying our proposed DePA approach on the representative vanilla NAT, the highly competitive fully NAT model GLAT and current SOTA CTC-DSLPMT for fully NAT models, but we have yet to apply DePA to iterative NAT models, such as Imputer (Saharia et al., 2020), CMLM (Ghazvininejad et al., 2019), and Levenshtein Transformer (Gu et al., 2019). Hence, the effectiveness of DePA on iterative NAT models still needs to be verified. Secondly, we have not yet incorporated reranking approaches such as Noisy Parallel Decoding (NPD) (Gu et al., 2018) into DePA. Thirdly, our proposed method FBD requires multiple additional training phases before NAT training, resulting in longer training time and using more GPU resources. Reducing the computational cost of FBD training is one future work that will be beneficial for energy saving. Last but not least, NAT models have limitations on handling long text. They suffer from worse translation quality when translating relatively long text. We plan to investigate all these topics in future work."
5,"Our training schedule introduces a language discriminator loss to impose constraints on the intermediate translation in the back-translation period. The experimental results suggest that our method can alleviate the copying problem when the involved languages are distant language pairs or lack training data. However, for language pairs that are not distant, and especially high-resource languages, our model does not show improvement over the baseline. Due to time and resource limitations, we do not further explore whether the optimal weight
for the language discriminator loss can have a connection with the size of the dataset and the involved language pairs. For example, for WMT En-De or En-Fr pairs, the languages are not distant language pairs and therefore we might obtain better results if the weights are slightly smaller. We believe that future research could explore this direction: to adapt the weight to different language pairs and the size of the training data. In addition, we do not conduct hyperparameter search for other hyperparameters, instead directly using suggested values.
In this work, we propose a novel training schedule that tries to address the copying problem, which is common among distant language pairs in UNMT. We experiment with high-resource languages English, German, French, Russian and Chinese, and low-resource languages including Gujarati and Kazakh. The training data we use is monolingual text extracted from online newspapers and released for the WMT series of shared tasks. As far as we know, all the monolingual corpora do not contain any metadata and therefore it would be unlikely that anyone can use the concerned data to attribute to specific individuals."
6,"limitations of these self-supervised pre-trained speech models while fine-tuning them on downstream speech translation tasks. acknolwedgements we are thankful to the organizers of the iwslt 2023 low resource and dialectal shared tasks. this work was generously supported by nsf grant iis-2125466 and by a meta sponsored research award. we are also thankful to the office of research computing at george mason university (https://orc.gmu.edu), funded in part by grants from the national science foundation (awards number 1625039 and 2018631), for the computing resources we used to train our models."
7,"limitations while our method is effective in zero-shot settings, we find that it has limited implications in supervised settings. this is because improving zero-shot translation presents a tug-of-war between language-agnostic and language-specific representations, each of which has a distinct effect on the model. another major downside is reduced training speed relative to the baseline many-to-many model. we note that this is an artifact of the agreement loss (kldiv.) which entails two forward-passes for each update. finally, in the present work, we compute k-nns for every source word in a sentence. although this has yielded strong results, we would like to explore a more explainable setting where k-nns can be applied to specific source words. we leave such explorations to future work."
8,"limitations and future work since our auxiliary target-side lm decoder is spawned with the same configuration as the mt decoder, this significantly adds to the model size at training time. this makes it difficult to scale/slower to train with translation models of large size. while this problem can be easily mitigated by using a gpu of larger memory, we would like to explore more efficient ways of incorporating the target context which we leave for future work. secondly, even though our method gives a significant boost to translation quality in the early latencies, it relies on the mma (ma et al., 2020) policy that has some limitations in terms of latency because of a suboptimal decision making using multiple heads (indurthi et al., 2022). while our policy shows improvement, it could be further optimized, for instance, in following reference alignments more closely which would have a positive effect on latency. finally, using additional monolingual data is also a viable direction for future work to strengthen the language model used in the approach."
9,"limitations the proposed method has several limitations that should be taken into consideration when employing it. first, the method relies on an existing model, e.g., k-means, which creates a dependency between the performance of the initial and the robust models. second, the flow is not trained end-to-end, which can also limit its performance as end-to-end training allows improvement of the robustness of the whole representation. lastly, to fully assess the effectiveness of the method, multiple metrics need to be examined. this can be a limitation as interpreting the results from multiple metrics may not be straightforward. however, it gives a more complete picture of the model’s performance."

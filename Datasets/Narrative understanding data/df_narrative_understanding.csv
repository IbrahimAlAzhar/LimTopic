,Text
0,"The dataset used in this work is a personal narrative corpus in English collected in-vitro (e.g. subjects in a lab setting). Further work will be needed to extend it to other languages, genres, and naturalistic conditions. The reproducibility of the annotation task may be subject to variability due to the fact that the task is done by five internal annotators and not through crowd-sourcing techniques."
1,"Due to various constraints, our experiments are only able to cover five non-linear novels and nine linear novels, listed in Table 7. This pales in comparison to the thousands of novels typically expected of large-scale studies in digital humanities, whose scale allows them to make generalizable claims regarding narratives or literary history (Piper et al., 2021). We hope to make up for this gap in our future work. One key challenge to scaling our dataset would be data availability. The use of non-linearity in fiction is predominantly a 20th century phenomenon, which suggests that many non-linear novels will not be in the public domain for some time to come.
In terms of experiment design, an important limitation of the quantitative evaluations in Section 4.2 is its assumption that a novel’s chapter divides provided by its author could be thought of as a form of “gold standard” labels for model validation. This claim of authorial control and “authority” over the text has been thoroughly problematized in literary studies since the emergence of poststructuralism (Barthes, 1967; Foucault, 1969), while analogous suspicions have been raised in natural language generation against the assumed reliability of human evaluators (Clark et al., 2021). Unfortunately, the author’s input is the only operationalizable criteria for ground truth available to us within the scope of this study."
2,"limitations that need to be acknowledged. first, our approach relies on a reductive representation of the narrative texts, overlooking all traditional stylometric measures. the perception of literary quality is an intricate concept that relies on numerous factors, ranging from the stylistics, characters, plot development and pace, to cultural contexts. by reducing each narrative text to a subset of chosen features, our approach inevitably discards much of the richness and subtlety of works, while the narrow range facilitated by goodreads’ scores forces the models to discern nuanced differences in perceived quality among texts that may be considered generally good by readers. this clearly limits our understanding of literary quality, especially when it comes to the more linguistically or stylistically virtuous titles. secondly, the reliance on goodreads scores as the sole metric of quality introduces bi- ases, as these scores are inevitably influenced by factors such as genre preferences and reader demographics. finally, the analysis is based on a limited sample of english-language texts from the 19th and 20th centuries, potentially limiting the generalizability of our findings to other periods, languages, or contexts. for the same reason, our study cannot consider the potential impact of translation and its effect on the reception of the texts. at the same time, given the inherent complexity of these constraints and the subjective nature of literary evaluation, the performances achieved by our models in terms of r2 scores and mean squared errors, which would be modest for easier tasks, can be considered rather promising. naturally, there is much that can be done from here. in the future, we intend to compile an even larger data set, in terms of both texts and features. integrating stylometric and syntactic features, for instance, could provide additional insights into the complex nature of literary quality. furthermore, we plan to investigate genre-specific patterns, as observing the performance of our models across different genres may reveal unique patterns and relationships that are specific to particular types of literature. finally, we intend to use more diverse and sophisticated metrics than goodreads: exploring alternative sources such as anthologies, awards, and canon lists. leveraging a richer set of indicators for literary quality/qualities, we hope to gain clearer insights into the complex interplay of factors that contribute to the perception of literary quality."
3,"limitations corpus. in this paper, we use fiction novels from multiple languages in project gutenberg. one assumption of this work is that the text is representative of the culture surrounding the language. while this may or may not be true (e.g. handler and segal, 1999), our investigation’s focus is on the structure, or narrative arc, of stories and how arcs may differ across languages. naturally, our findings may differ for other genres, such as history or self-help. we focus on fiction because the vast majority of research on narratives has focused on fiction, though we believe non-fiction and other genres would be interesting for future work. future work can also consider the addition of other corpora to enhance project gutenberg, such as megalite moreno-jiménez et al. (2021), a corpus of about 5,000 spanish, french, and portuguese narrative texts, poetry, or plays. however, multilingual corpora of this kind are few and far between, even for high-resource languages like spanish and french. dictionaries. this work heavily relies on liwc, which is proprietary software. many researchers (including ourselves) may not have access to all liwc dictionaries. in addition, as a dictionary of psychometric properties, liwc is constantly evolving and improving with new research in psychology and linguistics."
4,"limitations this paper presents the conceptual foundations of a novel architecture for narrative-based language understanding, along with an illustrative proof-ofconcept implementation. as such, it has been operationalised on a small scale only. scaling up the approach to real-world applications is a highly non-trivial task that would not only require large investments but also significant innovative research efforts. moreover, important aspects of the theoretical model have not been included in the proofof-concept implementation, in particular when it comes to modelling the confidence of an agent with respect to its beliefs and narratives."
5,limitations this is a position paper thus we do not see what the potential limitations could be. the only potential limitation might be the incompleteness of the list of relevant publications.
6,"limitations some of the limitations of this dataset include that of much of the time periods and locations given are simply approximations of the time period that the work is actually set in; this is most notable in the case of library of congress and wikipedia labels which make up the majority of the work. these datasets offer more coarse-grained settings of a work, such as years and geolocation, which have limitations for some purposes. an additional limitation is that the works are in english and also are more commonly set/written in the west, which should be taken into account when used for analytics."
7,"limitations several limitations relate to the study setups. one shortcoming is the small number of comics used in the experiments. while this is adequate for initial exploration into animate entity identification, these results cannot be generalised - comics in particular have an incredible number of potential types of animate entities and beings, and four comic stories do not touch on most of them. another limitation is the reliance on crowd-sourced recruitment and remote annotation. the researcher is not able to instruct the annotators in person and check their understanding of the annotation scheme. although the annotation task are seemingly relatively simple at this point, word-of-mouth recruitment of annotators who are more familiar with annotation processes are likely a better choice in future work, especially as the annotation scheme develops to include more complicated concepts. more significantly, the outlining method for identifying animate entities does not capture inanimate entities that become animate, as discussed in section 1.1. an annotator using the scheme tested here would not outline the sofa in figure 1, although the sofa should be included in an annotated corpus to capture an important update to the reader’s mental model. while these experiments show that these updates are somewhat obtained through interpreting reader feedback about their outlines, the limitations in developing an annotation scheme solely from the reader’s perspective are apparent. developing a comparable annotation scheme from the creator’s perspective may facilitate fuller analyses of narrative structures. since a creator knows that the sofa and kamala kahn are linked through coreference, both would be outlined and given the same reference label. integrating these two perspectives into one corpus could give insights into how creator’s intentions to communicate larger narrative structures are expressed in lower-level configurations of image and text."
8,"limitations of our pipeline’s output on mrs. dalloway shown in figure 1, we follow the approach of wang and iyyer (2019) to present the outcomes for literary close reading alongside quantitative metrics."
9,"limitations since dall•e mini is trained on english-language material, and since our input text is english only, our proposed methods will only be able to measure the imageability of english isolated words and connected text. the text-to-image model we use, dall•e mini, requires gpus or tpus to generate images. while we used 4 gpus (see section 4 for more details) to obtain the results in this paper, we were able to use a single gpu to successfully run the same experiments with longer runtime."

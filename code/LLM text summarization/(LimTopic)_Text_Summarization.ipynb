{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "load the dataset which generated by BERTopic"
      ],
      "metadata": {
        "id": "xS5fcDmoKIw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('df_bertopic.csv')"
      ],
      "metadata": {
        "id": "Mu0Wg9ENKIlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1-Z7nh2oNw5"
      },
      "source": [
        "# summarization (gpt 3.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WR4WYDUZfSj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# from langchain.agents import create_csv_agent\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from IPython.display import display, Markdown\n",
        "import dotenv\n",
        "import openai\n",
        "import pandas as pd\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "import pandas as pd\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7msyj2qqbGug"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = 'api_key'\n",
        "\n",
        "agent = create_pandas_dataframe_agent(\n",
        "    ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\"),\n",
        "    df,\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC8_aX9vHm8N"
      },
      "source": [
        "130 - 140 words"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Set up OpenAI client\n",
        "client = OpenAI(\n",
        "    api_key=os.environ.get(\"api_key\"),\n",
        ")\n",
        "\n",
        "# Create an empty list to store the generated summaries\n",
        "turbo_instruct_summaries = []\n",
        "\n",
        "# Iterate through each row in the DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    # Use the 'abstract' column content in the prompt\n",
        "    if index < 35:\n",
        "      prompt = f\"Summarize the following text with more weights in limitation within 130-140 words: {row['Representation']}\"\n",
        "\n",
        "      # Call OpenAI API to get the summary\n",
        "      response = client.completions.create(\n",
        "          model=\"gpt-3.5-turbo-instruct\",\n",
        "          prompt=prompt,\n",
        "          max_tokens=140  # Adjust as needed for summary length\n",
        "      )\n",
        "\n",
        "      # Extract the summary from the API response\n",
        "      summary = response.choices[0].text.strip()\n",
        "\n",
        "      # Add the summary to the list\n",
        "      turbo_instruct_summaries.append(summary)\n",
        "      time.sleep (5)\n",
        "\n",
        "turbo_instruct_summaries\n"
      ],
      "metadata": {
        "id": "DRDCzT6ouTf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDnL8mXE2orJ",
        "outputId": "676a8557-7733-480d-f60a-eb3f8376cf5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(turbo_instruct_summaries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlX0wLII62o9",
        "outputId": "d76f5d83-d737-49f2-98a2-f573f844b2a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The limitations of language model research include the use of limited, labeled training data to train autoencoders, which may not accurately represent real-world usage. Additionally, the evaluation of generation quality and generality is limited to a small number of tasks and datasets, and the interpretability and robustness of models still need to be further analyzed. Due to computational constraints, the performance of the proposed method has only been tested at a single model scale. Language models are also not guaranteed to generate truthful information and can introduce noisy or biased information, affecting the quality of the generated affective events. Furthermore, the reported results may not accurately reflect the performance on unmasked or differently masked inputs, as the evaluation process',\n",
              " 'The use of transformer models for multilingual language processing is limited by the need for extensive parallel corpora for effective machine translation. While transfer learning has shown more promising results for low-resource indigenous languages, it still has its limitations. Pretraining on high-resource languages and fine-tuning on indigenous languages often leads to unsatisfactory performance and persistent errors. Additionally, the use of wikidata for creating benchmarks can introduce linguistic and cultural bias towards English-speaking cultures. There is a need for native benchmarking in linguistically diverse languages to accurately evaluate multilingual information access. The evaluation of cross-lingual transfer also relies heavily on currently available multilingual benchmarks, limiting the development of better models for underrepresented languages',\n",
              " 'The paper outlines a framework for assessing and improving the quality of dialogue systems focused on everyday living activities. A dataset of human-written questions and answers with profile information was created, but is limited due to factual inconsistencies and the need for expansion. The use of deep neural networks can lead to better performance, but the trade-offs between model size and deployment environment must be considered for a smooth user experience. To address this, the dataset will be further labeled and expanded, and methods such as knowledge distillation will be explored to reduce the model size. However, the proposed metric is primarily designed for turn-level evaluation and may not generalize to other scenarios, such as dialogue-level evaluation or human-chatbot interactions. Additionally',\n",
              " 'The discussions on limitations in artificial intelligence models focus on the integration and analysis of multimodal data, including images, text, and potentially other modalities like audio and video. These limitations include resource constraints when using specific pre-trained models, lack of dataset diversity mainly in English and vision-language tasks, and the need for better alignment and fusion methods between different modalities. Further, the limitation of not having comprehensive datasets covering a broad range of modalities and tasks is highlighted. Addressing these limitations is crucial for future AI advancements and can be achieved through improving multimodal dataset collection, enhancing model flexibility, and integrating multiple modalities.',\n",
              " \"This paper provides an overview of reasoning in large language models, specifically focusing on deductive reasoning due to its prominence in the literature. Other forms of reasoning like inductive and abductive reasoning are not discussed in depth. The proposed reasoning circuit framework aims to replace the need for large amounts of annotated examples by using structured rationales. However, there are two issues with this approach: difficulty in breaking down multi-step reasoning problems into discrete steps and increasing complexity of the circuit with task complexity. The selection of concepts for this framework is limited by the availability of semi-structured explanations, which may not represent the vast range of concepts that users expect models to learn from context. The researchers' computational resources, financial\",\n",
              " \"The paper focuses on query-focused meeting summarization task and explores the rankergenerator framework's performance on long-input summarization task. The results do not show significant improvement, and the qmsum dataset also faces the long-input challenge. However, due to the specific parts summarization in qfms task, it can be used as input while long-input summarization task aims to generate an overall summary. Other tasks like long-document summarization may benefit more from controllable summarization. For this, they applied the segenc architecture on top of bart, which may have dampened some of the few-shot performance of socratic pretraining. Static-dynamic graph-based dialogue summarization method was proposed\",\n",
              " 'The multi-hop QA models have been successful in improving their capabilities, but they still have a number of limitations that must be addressed. The primary dataset used for the study, 2wikihopmultiqa, only allows for 2-hop analysis, limiting the potential for 3-4 hop questions. Additionally, the models are restricted to around 500 tokens, making them unsuitable for longer documents. This means they can only generate short answers and single-hop questions. The models are also limited to English, which makes it challenging to apply the same approach in other languages. The success of the knowledge-augmentation framework also relies heavily on the effectiveness of the retrievers. If the retriever',\n",
              " 'The use of interdapt in NER may be limited due to its dependence on the quality of the target sub-domain datasets and entity labels, making it difficult to accurately measure performance improvements. Although it may reduce data annotation costs, interdapt still requires specific data for each domain. While publicly available datasets can be used, they may not accurately simulate real-world scenarios, as not all text in target languages contain predefined named entities - requiring additional data cleaning and preprocessing. Additionally, there may be situations where entity classes overlap, causing difficulties in training. Furthermore, the proposed self-training method may not be fully applicable to real-life settings, and further evaluation is necessary to determine its compatibility with other models.',\n",
              " 'The paper discusses defense strategies against adversarial attacks in NLP applications, specifically focusing on word substitution attacks. However, these strategies have limitations such as being tested on downstream task models only and being dependent on strong models like BERT. Additionally, the effectiveness of the strategies is hindered by short and susceptible text which is easily recognized by humans, highlighting the need for human verification. The study primarily focuses on identifying robust overfitting in PRLMs using PGD attacks instead of textual adversarial attacks. The results may not be generalizable due to different strategies being integrated. Furthermore, the transferability of strategies to non-pretrained models is still unknown, and only PGD attacks have been tested.',\n",
              " 'The study mentioned in the text has various limitations that affect the validity of the results. These include a limited patient sample size from a single hospital, which may not be representative of the general population. This could lead to biased results due to differences in gender, age, and race. Additionally, obtaining high-quality data for NLP models in the medical field is challenging due to privacy concerns and the technical nature of medical language. This can affect the accuracy of the results. Evaluating automatically generated clinical notes also poses difficulties due to the subjective nature of output quality and the limitations of automatic evaluation metrics. Even human evaluation by expert physicians may not be completely reliable. Overall, while NLP technology has potential in',\n",
              " 'Transformer-based models have shown great potential in various natural language processing tasks, however, there are limitations to consider. Firstly, other components besides bias parameters are not taken into account in the prediction head. Additionally, the findings of this study only pertain to BERT and GPT-2, therefore it is uncertain if they can be applied to other transformer models such as Roberta or open pre-trained ones. Moreover, due to computational constraints, the automoe search space and evaluation were limited to big-sized transformer models for benchmark machine translation tasks. These limitations hinder the exploration of larger and more efficient moe models with billions to trillions of parameters. Furthermore, there is a lack of standardized benchmarks for',\n",
              " 'The limitation of the proposed method lies in its reliance on an additional mental health related knowledge graph, which may be difficult to obtain. The approach is also limited in its evaluation to argumentative tasks and English data, despite its potential applicability in other domains and languages. Another limitation is the scope of knowledge graph resources that can be modeled, as embedding-based methods do not easily capture attributes, descriptions, and images. Future research should consider a broader range of data types and complementary methods to effectively incorporate them. Additionally, the reliance on explicit knowledge in the knowledge graph may limit the effectiveness of the approach, as there is a plethora of implicit knowledge in unstructured resources. This may be addressed by considering implicit',\n",
              " 'The documents highlight the difficulties and approaches involved in event extraction (EE) and representation within natural language processing (NLP). They emphasize the importance of utilizing annotations, event temporal relations, and machine learning models like pretrained language models and graph neural networks to enhance event understanding. Some of the major issues addressed by these methods include data scarcity, the need for open-domain frameworks, and the construction of temporal event graphs. However, the limitations of these methods, such as their dependency on pre-identified event triggers and arguments, and the lack of exploration into hierarchical events, are also acknowledged.',\n",
              " 'One of the main limitations of contextual and sense embedding models is the use of a purely lexical approach, which does not take into account the context in which a word appears. This leads to miscounting of words with specific senses in certain contexts, which could be addressed by a more advanced mapping method. Another limitation is the use of a manually generated filtering list, which may still have some limitations for the GRM model. While this model does bring some improvements, they are relatively small compared to static models and may even harm the performance of other models. Furthermore, the source sense embeddings used in experiments are only for the English language, limiting their applicability to other languages. Lastly, there is no',\n",
              " 'The topic of bias and limitations in AI-driven hate speech detection is explored in these documents. Ethical concerns and challenges are discussed, especially regarding the reliance on English data and potential biases in machine-generated data. The focus on specific types of fairness-related harms and the accuracy of human annotations are also addressed. However, these discussions highlight the limitations of current experiments and the need for cautious application of AI models like GPT-3. The societal impacts of these biases are also emphasized, and it is suggested that future work should focus on refining bias identification and mitigation in AI systems. Overall, while AI has the potential to identify and mitigate hate speech, it is important to acknowledge and address its current limitations and',\n",
              " 'The scientific research datasets used in this study are limited to those accessed through the Microsoft Academic Graph and S2ORC, which may not fully represent all collections of scientific text. Additionally, the data mostly focuses on international English language NLP conferences and may not include relevant research published in other venues or languages. The dataset also suffers from limitations such as only including papers with code and skewing the publication year of papers used. The review process was also restricted to only open-access venues and peer-reviewed papers, which may have excluded important preprints or workshop papers. These limitations may affect the validity and generalizability of the findings.',\n",
              " 'The dense retriever, while successful in passage retrieval for odqa, has limitations when used for other retrieval tasks with different input and output formats. It is also costlier to train compared to traditional sparse vector models. The effectiveness of hard negative sampling and number of negative samples for cwprf remains untested. Longer document retrieval can be addressed by splitting documents into passages, but this may affect query response. The proposed matching representation offers improvements in generalization ability, but further theoretical research is needed. Additionally, the study only focuses on a specific type of dense retriever and does not consider alternative approaches for retrieval. Furthermore, the analysis only covers bidirectional models trained in a contrastive fashion, although',\n",
              " \"The study uses large language models which result in high GPU resource costs. They conducted experiments on an 8 x NVIDIA A100 GPU station with a maximum inference time of ~ 8 hours. The estimation of costed computing resources for this study is ~ 500 x 8 GPU hours. The GPUSQ-TLM compression scheme is heavily dependent on NVIDIA GPU's features, so deploying compressed models on different GPU types without this support may decrease efficiency. Only English language data was used for experiments and using BERT-classifier with AL is resource intensive. While their approach is effective, it is not the most efficient, and to find the most optimal compression techniques and evaluate their performance, hundreds of experiments\",\n",
              " 'The study discussing political and moral analyses on social media and texts has a few limitations. The first limitation is that the dataset used for analysis only includes 2000 tweets from a single social media platform, which may not represent the larger population. Furthermore, the data was manually filtered and may not accurately reflect the overall sentiment. Additionally, there is a risk of misuse of technology for morality classification, potentially targeting marginalized groups. The political compass test, used to gauge political leaning, is also not a perfect tool and may not fully represent political ideologies. Finally, the study relies heavily on dictionary-based analysis to measure moral content, which may not capture nuanced expressions and could be complemented with other methods. While',\n",
              " 'The main limitation of the meta-learning optimization study is the limited computation resources, which restricts the evaluation to only a few tasks from the glue and superglue benchmarks. These tasks do not accurately reflect a realistic few-shot setting, where training samples are limited and development sets are not provided.\\n\\nThe study also has limitations in the meta learning process, as the exhaustive search for hyperparameters is not feasible in all settings. This may result in underperformance of the multi-task learning method. Moreover, the computation of backward propagation required in the meta-learning process is more time-consuming than forward propagation, affecting both training and inference efficiency.\\n\\nThe use of meta-retriever for task-specific knowledge retrieval may also lead',\n",
              " 'The study of gender bias in language vision was limited in many aspects. Firstly, the findings were based on only two datasets, one task, one language, and a mostly western population. Moreover, the test set used in the third analysis was small due to the characteristics of the names. Additionally, the bias around naming choices was limited to the domain of sports only. Furthermore, the study only focused on one computational model and one task, masking language modeling. This could affect the generalizability of the results. The gender-tuning technique used to reduce bias only works on gender-related words, meaning it may not cover other potential gender biases. The approach also does not account for sentences that make sense',\n",
              " 'Knowledge distillation and model compression techniques have become increasingly popular for training efficient deep learning models. However, current knowledge distillation methods have significant limitations. They are often designed for specific teacher models, requiring additional pretraining, fine-tuning, or data augmentation. In contrast, our approach is simple and can be applied to any architecture or task. Additionally, we conducted our experiments on a relatively inexpensive GPU, showing that our method is both effective and cost-efficient. Nevertheless, our method may not be as effective as more specialized techniques, and there is a trade-off between efficiency and accuracy. Further research is needed to address these limitations and optimize knowledge distillation methods for various tasks.',\n",
              " \"The methodology for predicting emotional reactions to social posts displays promising results, but has limitations. The model only considers textual content and metadata, neglecting factors like user demographics and multimedia content that could affect prediction accuracy. Additionally, the study only focuses on predicting reactions, not understanding the reasons behind them. The reliance on pre-trained language models may also affect the performance of the approach, and the density of the user-product graph could impact the results. Furthermore, the study's dataset was primarily based on American respondents, which may not fully represent all users of WeChat and could be influenced by factors like familiarity with WeChat and Chinese culture. Lastly, the lack of a specific dataset for fine-grained emotional paraph\",\n",
              " 'The paper discusses the limitations and challenges in implementing zero-shot and supervised learning methods for text classification. While the proposed framework regen shows promising results, the experiment was conducted only on BERTbase-sized models and focused solely on zero-shot classification with task-specific verbalizers and unlabeled generic corpus. This makes it difficult to apply the framework to other tasks, such as natural language processing. Furthermore, the paper acknowledges that the results may not generalize well due to limited data and longer inference time. The approach also requires a compromise between supervised and unsupervised methods, making it less effective in both in-distribution and out-of-distribution settings. Additionally, collecting a large dataset for supervised or semi-supervised',\n",
              " \"The study found that utilizing revision-based data can effectively contribute towards solving challenges in detecting and improving claims. However, there are several limitations to these methods. The pipeline nature of the approach can propagate errors, and the dependency parser used is not as effective on informal texts. The definition of positive and negative effect relationships is shallow and may not reflect the complexity of real-world situations. There were also conflicts during the annotation process, leading to lower agreement levels and a need for interpretation in legal claims and premises. Furthermore, the methods cannot be directly applied to existing revision-based corpora from other domains due to limited data and metadata. Additional efforts would be needed to improve the approach's effectiveness.\",\n",
              " 'The autoregressive span selection strategy addresses the limitations of current span-based parsing methods by weakening the imposed conditional independence assumptions. However, it introduces another restrictive bias by forcing a predefined span selection order. While using post-order selection performs decently, it is not necessarily the best option and other potential orders remain unexplored. In addition, the non-deterministic nature of splitting points in discontinuous parsing can be challenging to handle. Moreover, there are two major limitations to the method: inadequate grammar constraints and prediction time. The use of a strong, general grammar and considering complex distributions could potentially improve results. Additionally, the assumption that both source-side and qcfg grammars are in CNF may',\n",
              " \"The privacy-enhancing techniques used in model training have some significant limitations that must be considered. This includes the use of closed-source models, which may not be acceptable in many settings due to the need to send data to third-party APIs. Technical limitations also restrict the effectiveness of these techniques, such as a focus on improving one particular approach and uncertainty about whether it can be applied to others. Additionally, training and implementing large models using differential privacy can be difficult and computationally intensive, rendering it inaccessible to many users. This is due to the need for per-example gradients and large batch sizes, which can limit the model's ability to learn from rare patterns in the training data. While the proposed method for\",\n",
              " 'NLP model comparison is limited in practical applications due to their confinement to artificial datasets, without clear implications on real-world tasks. The results only pertain to text classification and lack inclusion of other NLP problems. The experiments were limited to fixed strings and did not consider a wider range of tasks or task shifts. Environmental concerns and practical limitations prevent the study from including models larger than t5-large, preventing a comparison of emergent properties. Therefore, the findings are primarily applicable to low-resource scenarios and may not be representative of larger models. However, the study does provide valuable insights into the performance of mlp-based architectures in text classification tasks under constrained compute budgets. There is a need for further research',\n",
              " 'The collection of documents on metaphor and figurative language processing covers various aspects, including visual metaphor generation, cross-lingual analysis, and reasoning in text puzzles. While there is potential for human-AI collaboration in visual metaphor generation, the limitations and challenges, such as cultural context and reliance on paid APIs, are also discussed. Additionally, the need for more comprehensive consideration of language and figurative speech, diversity in metaphor generation, and exploration of diverse lexical units is highlighted. These challenges indicate a need for further progress in the field and demonstrate the complexities involved in accurately processing metaphors and figurative language.',\n",
              " 'The proposed uncertainty-aware bootstrap learning framework for joint extraction achieves state-of-the-art performance but requires large training resources due to the ensemble loss and probability variance calculation. The constructed corpus integrates RE with NER and aims to measure the impact of NER on relation extraction through multi-task learning. However, due to limited size, experiments on SSI were not conducted. Advancements in information extraction are limited by the slow inference stage, lack of interaction and heterogeneous embedding spaces, and the need for an extra module in identifying relations. To address these issues, a unified textual entailment framework called TEA is proposed, which transforms relational and attribute triples into textual sequences and models the EA task as a bi-directional',\n",
              " 'The documents address the obstacles and restrictions in instructing AI systems, such as chatgpt, to comprehend and produce humor, including sarcasm and jokes. The difficulties entail the subjective nature of humor, differentiating between legitimate errors and mistakenly assigned significance by automated systems, and the incorporation of multimodal data like text within images. Additionally, the tendency of AI to generate persuasive yet inaccurate explanations is also highlighted. Key areas of focus include the particular challenges of detecting irony and sarcasm in text, reliance on insufficient datasets and pre-trained models, and the examination of humor characteristics in AI-generated material. Overall, limitations lie in the subjective and complex nature of humor, as well as the limitations of current AI',\n",
              " 'This study aims to identify anorexia, self-harm, and depression in social media users using a language model. However, the reliability of the results may be limited as the model and baseline models were trained on social media texts and tested on online text. Therefore, the findings may not accurately reflect real-life clinical settings. The paper also focuses on automatically detecting depressive symptoms from memes on social media, but the sample used may have similar limitations to other datasets focusing on naturalistic behavior related to a specific event.',\n",
              " 'The main idea of promptrank is to use a designed prompt to rank candidates in natural language processing. However, experiments show that a decoder-only model is more suitable for prompts generated by co-prompt. Despite strong results, residual prompt tuning has limitations, as its performance is not as good as fine-tuning and it requires more parameters to train. Additionally, the focus is on tasks with simple instructions, which may pose a greater evaluation challenge. The overall goal is to study instruction induction in lab conditions, which is limited by the simplicity of the tasks. This suggests that the effectiveness of promptrank may vary depending on the complexity of the task.',\n",
              " 'One limitation of the study is that the chosen fairness metrics may not accurately capture all aspects of bias and must be carefully selected for the specific context and task at hand. This highlights the importance of having experts in the field to fully understand and interpret the bias. The use of social bias benchmarks in the study also raises concerns about their underlying assumptions and potential cultural biases. Additionally, the study only focuses on biases present in contemporary English language, potentially overlooking cross-cultural differences in stereotypes. The use of human-collected lists for counterfactual data augmentation and intervened distribution generation may not cover all relevant demographic groups. There is potential for improvement in the model by considering more diverse perspectives and demographic axes.',\n",
              " 'The focus of the documents is on the challenges faced in enhancing efficiency and decreasing computational complexity in Neural Machine Translation (NMT). These challenges include the expensive computational costs of SSMT models due to additional decoding steps, the slower decoding speeds and lower sample efficiency of SSD-LM models compared to AR-LM models, the inability to apply the DEPA approach to different NMT models, and the significant memory and storage requirements of using kNN-MT for faster decoding without addressing other underlying issues. These limitations suggest that further research and development is needed to overcome these obstacles and improve the overall efficiency of NMT models.']"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "turbo_instruct_summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXTAqay44AzL",
        "outputId": "61efd244-f834-41ee-b5ff-0e588fe047a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzA9wPcp-hMr"
      },
      "outputs": [],
      "source": [
        "df_gpt_3_summary = pd.DataFrame(turbo_instruct_summaries, columns=['Text'])\n",
        "df_gpt_3_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCp9Nua5_IKN"
      },
      "source": [
        "# gpt4 summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69DrY2m-rmHC"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain\n",
        "!pip -q install openai\n",
        "!pip -q install python-dotenv\n",
        "!pip -q install langchain_openai\n",
        "!pip -q install tiktoken\n",
        "!pip -q install langchain_experimental\n",
        "!pip -q install langchain[all]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcVxypy1rmHC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from IPython.display import display, Markdown\n",
        "import dotenv\n",
        "import openai\n",
        "import pandas as pd\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "import pandas as pd\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-79aGPQGltW"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = 'api_key'\n",
        "\n",
        "agent = create_pandas_dataframe_agent(\n",
        "    ChatOpenAI(temperature=0, model=\"gpt-4-1106-preview\"),\n",
        "    df,\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srSQ-yAA_Kld"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=os.environ.get(\"api_key\"),\n",
        ")\n",
        "\n",
        "# Create an empty list to store the generated summaries\n",
        "turbo_instruct_summaries = []\n",
        "\n",
        "# Iterate through each row in the DataFrame\n",
        "for index, row in df.iterrows():\n",
        "    if index < 35:\n",
        "      prompt = f\"Summarize the following text with more weights in limitation: {row['Representation']}\"\n",
        "\n",
        "      # Call OpenAI API to get the summary\n",
        "      response = client.completions.create(\n",
        "          model=\"gpt-4-1106-preview\",\n",
        "          prompt=prompt,\n",
        "          max_tokens=150  # Adjust as needed for summary length\n",
        "      )\n",
        "\n",
        "      # Extract the summary from the API response\n",
        "      summary = response.choices[0].text.strip()\n",
        "\n",
        "      # Add the summary to the list\n",
        "      turbo_instruct_summaries.append(summary)\n",
        "      time.sleep (5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO8DQJcB_Kli",
        "outputId": "676a8557-7733-480d-f60a-eb3f8376cf5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(turbo_instruct_summaries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uuyd0qC_Kli",
        "outputId": "d76f5d83-d737-49f2-98a2-f573f844b2a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The limitations of language model research include the use of limited, labeled training data to train autoencoders, which may not accurately represent real-world usage. Additionally, the evaluation of generation quality and generality is limited to a small number of tasks and datasets, and the interpretability and robustness of models still need to be further analyzed. Due to computational constraints, the performance of the proposed method has only been tested at a single model scale. Language models are also not guaranteed to generate truthful information and can introduce noisy or biased information, affecting the quality of the generated affective events. Furthermore, the reported results may not accurately reflect the performance on unmasked or differently masked inputs, as the evaluation process',\n",
              " 'The use of transformer models for multilingual language processing is limited by the need for extensive parallel corpora for effective machine translation. While transfer learning has shown more promising results for low-resource indigenous languages, it still has its limitations. Pretraining on high-resource languages and fine-tuning on indigenous languages often leads to unsatisfactory performance and persistent errors. Additionally, the use of wikidata for creating benchmarks can introduce linguistic and cultural bias towards English-speaking cultures. There is a need for native benchmarking in linguistically diverse languages to accurately evaluate multilingual information access. The evaluation of cross-lingual transfer also relies heavily on currently available multilingual benchmarks, limiting the development of better models for underrepresented languages',\n",
              " 'The paper outlines a framework for assessing and improving the quality of dialogue systems focused on everyday living activities. A dataset of human-written questions and answers with profile information was created, but is limited due to factual inconsistencies and the need for expansion. The use of deep neural networks can lead to better performance, but the trade-offs between model size and deployment environment must be considered for a smooth user experience. To address this, the dataset will be further labeled and expanded, and methods such as knowledge distillation will be explored to reduce the model size. However, the proposed metric is primarily designed for turn-level evaluation and may not generalize to other scenarios, such as dialogue-level evaluation or human-chatbot interactions. Additionally',\n",
              " 'The discussions on limitations in artificial intelligence models focus on the integration and analysis of multimodal data, including images, text, and potentially other modalities like audio and video. These limitations include resource constraints when using specific pre-trained models, lack of dataset diversity mainly in English and vision-language tasks, and the need for better alignment and fusion methods between different modalities. Further, the limitation of not having comprehensive datasets covering a broad range of modalities and tasks is highlighted. Addressing these limitations is crucial for future AI advancements and can be achieved through improving multimodal dataset collection, enhancing model flexibility, and integrating multiple modalities.',\n",
              " \"This paper provides an overview of reasoning in large language models, specifically focusing on deductive reasoning due to its prominence in the literature. Other forms of reasoning like inductive and abductive reasoning are not discussed in depth. The proposed reasoning circuit framework aims to replace the need for large amounts of annotated examples by using structured rationales. However, there are two issues with this approach: difficulty in breaking down multi-step reasoning problems into discrete steps and increasing complexity of the circuit with task complexity. The selection of concepts for this framework is limited by the availability of semi-structured explanations, which may not represent the vast range of concepts that users expect models to learn from context. The researchers' computational resources, financial\",\n",
              " \"The paper focuses on query-focused meeting summarization task and explores the rankergenerator framework's performance on long-input summarization task. The results do not show significant improvement, and the qmsum dataset also faces the long-input challenge. However, due to the specific parts summarization in qfms task, it can be used as input while long-input summarization task aims to generate an overall summary. Other tasks like long-document summarization may benefit more from controllable summarization. For this, they applied the segenc architecture on top of bart, which may have dampened some of the few-shot performance of socratic pretraining. Static-dynamic graph-based dialogue summarization method was proposed\",\n",
              " 'The multi-hop QA models have been successful in improving their capabilities, but they still have a number of limitations that must be addressed. The primary dataset used for the study, 2wikihopmultiqa, only allows for 2-hop analysis, limiting the potential for 3-4 hop questions. Additionally, the models are restricted to around 500 tokens, making them unsuitable for longer documents. This means they can only generate short answers and single-hop questions. The models are also limited to English, which makes it challenging to apply the same approach in other languages. The success of the knowledge-augmentation framework also relies heavily on the effectiveness of the retrievers. If the retriever',\n",
              " 'The use of interdapt in NER may be limited due to its dependence on the quality of the target sub-domain datasets and entity labels, making it difficult to accurately measure performance improvements. Although it may reduce data annotation costs, interdapt still requires specific data for each domain. While publicly available datasets can be used, they may not accurately simulate real-world scenarios, as not all text in target languages contain predefined named entities - requiring additional data cleaning and preprocessing. Additionally, there may be situations where entity classes overlap, causing difficulties in training. Furthermore, the proposed self-training method may not be fully applicable to real-life settings, and further evaluation is necessary to determine its compatibility with other models.',\n",
              " 'The paper discusses defense strategies against adversarial attacks in NLP applications, specifically focusing on word substitution attacks. However, these strategies have limitations such as being tested on downstream task models only and being dependent on strong models like BERT. Additionally, the effectiveness of the strategies is hindered by short and susceptible text which is easily recognized by humans, highlighting the need for human verification. The study primarily focuses on identifying robust overfitting in PRLMs using PGD attacks instead of textual adversarial attacks. The results may not be generalizable due to different strategies being integrated. Furthermore, the transferability of strategies to non-pretrained models is still unknown, and only PGD attacks have been tested.',\n",
              " 'The study mentioned in the text has various limitations that affect the validity of the results. These include a limited patient sample size from a single hospital, which may not be representative of the general population. This could lead to biased results due to differences in gender, age, and race. Additionally, obtaining high-quality data for NLP models in the medical field is challenging due to privacy concerns and the technical nature of medical language. This can affect the accuracy of the results. Evaluating automatically generated clinical notes also poses difficulties due to the subjective nature of output quality and the limitations of automatic evaluation metrics. Even human evaluation by expert physicians may not be completely reliable. Overall, while NLP technology has potential in',\n",
              " 'Transformer-based models have shown great potential in various natural language processing tasks, however, there are limitations to consider. Firstly, other components besides bias parameters are not taken into account in the prediction head. Additionally, the findings of this study only pertain to BERT and GPT-2, therefore it is uncertain if they can be applied to other transformer models such as Roberta or open pre-trained ones. Moreover, due to computational constraints, the automoe search space and evaluation were limited to big-sized transformer models for benchmark machine translation tasks. These limitations hinder the exploration of larger and more efficient moe models with billions to trillions of parameters. Furthermore, there is a lack of standardized benchmarks for',\n",
              " 'The limitation of the proposed method lies in its reliance on an additional mental health related knowledge graph, which may be difficult to obtain. The approach is also limited in its evaluation to argumentative tasks and English data, despite its potential applicability in other domains and languages. Another limitation is the scope of knowledge graph resources that can be modeled, as embedding-based methods do not easily capture attributes, descriptions, and images. Future research should consider a broader range of data types and complementary methods to effectively incorporate them. Additionally, the reliance on explicit knowledge in the knowledge graph may limit the effectiveness of the approach, as there is a plethora of implicit knowledge in unstructured resources. This may be addressed by considering implicit',\n",
              " 'The documents highlight the difficulties and approaches involved in event extraction (EE) and representation within natural language processing (NLP). They emphasize the importance of utilizing annotations, event temporal relations, and machine learning models like pretrained language models and graph neural networks to enhance event understanding. Some of the major issues addressed by these methods include data scarcity, the need for open-domain frameworks, and the construction of temporal event graphs. However, the limitations of these methods, such as their dependency on pre-identified event triggers and arguments, and the lack of exploration into hierarchical events, are also acknowledged.',\n",
              " 'One of the main limitations of contextual and sense embedding models is the use of a purely lexical approach, which does not take into account the context in which a word appears. This leads to miscounting of words with specific senses in certain contexts, which could be addressed by a more advanced mapping method. Another limitation is the use of a manually generated filtering list, which may still have some limitations for the GRM model. While this model does bring some improvements, they are relatively small compared to static models and may even harm the performance of other models. Furthermore, the source sense embeddings used in experiments are only for the English language, limiting their applicability to other languages. Lastly, there is no',\n",
              " 'The topic of bias and limitations in AI-driven hate speech detection is explored in these documents. Ethical concerns and challenges are discussed, especially regarding the reliance on English data and potential biases in machine-generated data. The focus on specific types of fairness-related harms and the accuracy of human annotations are also addressed. However, these discussions highlight the limitations of current experiments and the need for cautious application of AI models like GPT-3. The societal impacts of these biases are also emphasized, and it is suggested that future work should focus on refining bias identification and mitigation in AI systems. Overall, while AI has the potential to identify and mitigate hate speech, it is important to acknowledge and address its current limitations and',\n",
              " 'The scientific research datasets used in this study are limited to those accessed through the Microsoft Academic Graph and S2ORC, which may not fully represent all collections of scientific text. Additionally, the data mostly focuses on international English language NLP conferences and may not include relevant research published in other venues or languages. The dataset also suffers from limitations such as only including papers with code and skewing the publication year of papers used. The review process was also restricted to only open-access venues and peer-reviewed papers, which may have excluded important preprints or workshop papers. These limitations may affect the validity and generalizability of the findings.',\n",
              " 'The dense retriever, while successful in passage retrieval for odqa, has limitations when used for other retrieval tasks with different input and output formats. It is also costlier to train compared to traditional sparse vector models. The effectiveness of hard negative sampling and number of negative samples for cwprf remains untested. Longer document retrieval can be addressed by splitting documents into passages, but this may affect query response. The proposed matching representation offers improvements in generalization ability, but further theoretical research is needed. Additionally, the study only focuses on a specific type of dense retriever and does not consider alternative approaches for retrieval. Furthermore, the analysis only covers bidirectional models trained in a contrastive fashion, although',\n",
              " \"The study uses large language models which result in high GPU resource costs. They conducted experiments on an 8 x NVIDIA A100 GPU station with a maximum inference time of ~ 8 hours. The estimation of costed computing resources for this study is ~ 500 x 8 GPU hours. The GPUSQ-TLM compression scheme is heavily dependent on NVIDIA GPU's features, so deploying compressed models on different GPU types without this support may decrease efficiency. Only English language data was used for experiments and using BERT-classifier with AL is resource intensive. While their approach is effective, it is not the most efficient, and to find the most optimal compression techniques and evaluate their performance, hundreds of experiments\",\n",
              " 'The study discussing political and moral analyses on social media and texts has a few limitations. The first limitation is that the dataset used for analysis only includes 2000 tweets from a single social media platform, which may not represent the larger population. Furthermore, the data was manually filtered and may not accurately reflect the overall sentiment. Additionally, there is a risk of misuse of technology for morality classification, potentially targeting marginalized groups. The political compass test, used to gauge political leaning, is also not a perfect tool and may not fully represent political ideologies. Finally, the study relies heavily on dictionary-based analysis to measure moral content, which may not capture nuanced expressions and could be complemented with other methods. While',\n",
              " 'The main limitation of the meta-learning optimization study is the limited computation resources, which restricts the evaluation to only a few tasks from the glue and superglue benchmarks. These tasks do not accurately reflect a realistic few-shot setting, where training samples are limited and development sets are not provided.\\n\\nThe study also has limitations in the meta learning process, as the exhaustive search for hyperparameters is not feasible in all settings. This may result in underperformance of the multi-task learning method. Moreover, the computation of backward propagation required in the meta-learning process is more time-consuming than forward propagation, affecting both training and inference efficiency.\\n\\nThe use of meta-retriever for task-specific knowledge retrieval may also lead',\n",
              " 'The study of gender bias in language vision was limited in many aspects. Firstly, the findings were based on only two datasets, one task, one language, and a mostly western population. Moreover, the test set used in the third analysis was small due to the characteristics of the names. Additionally, the bias around naming choices was limited to the domain of sports only. Furthermore, the study only focused on one computational model and one task, masking language modeling. This could affect the generalizability of the results. The gender-tuning technique used to reduce bias only works on gender-related words, meaning it may not cover other potential gender biases. The approach also does not account for sentences that make sense',\n",
              " 'Knowledge distillation and model compression techniques have become increasingly popular for training efficient deep learning models. However, current knowledge distillation methods have significant limitations. They are often designed for specific teacher models, requiring additional pretraining, fine-tuning, or data augmentation. In contrast, our approach is simple and can be applied to any architecture or task. Additionally, we conducted our experiments on a relatively inexpensive GPU, showing that our method is both effective and cost-efficient. Nevertheless, our method may not be as effective as more specialized techniques, and there is a trade-off between efficiency and accuracy. Further research is needed to address these limitations and optimize knowledge distillation methods for various tasks.',\n",
              " \"The methodology for predicting emotional reactions to social posts displays promising results, but has limitations. The model only considers textual content and metadata, neglecting factors like user demographics and multimedia content that could affect prediction accuracy. Additionally, the study only focuses on predicting reactions, not understanding the reasons behind them. The reliance on pre-trained language models may also affect the performance of the approach, and the density of the user-product graph could impact the results. Furthermore, the study's dataset was primarily based on American respondents, which may not fully represent all users of WeChat and could be influenced by factors like familiarity with WeChat and Chinese culture. Lastly, the lack of a specific dataset for fine-grained emotional paraph\",\n",
              " 'The paper discusses the limitations and challenges in implementing zero-shot and supervised learning methods for text classification. While the proposed framework regen shows promising results, the experiment was conducted only on BERTbase-sized models and focused solely on zero-shot classification with task-specific verbalizers and unlabeled generic corpus. This makes it difficult to apply the framework to other tasks, such as natural language processing. Furthermore, the paper acknowledges that the results may not generalize well due to limited data and longer inference time. The approach also requires a compromise between supervised and unsupervised methods, making it less effective in both in-distribution and out-of-distribution settings. Additionally, collecting a large dataset for supervised or semi-supervised',\n",
              " \"The study found that utilizing revision-based data can effectively contribute towards solving challenges in detecting and improving claims. However, there are several limitations to these methods. The pipeline nature of the approach can propagate errors, and the dependency parser used is not as effective on informal texts. The definition of positive and negative effect relationships is shallow and may not reflect the complexity of real-world situations. There were also conflicts during the annotation process, leading to lower agreement levels and a need for interpretation in legal claims and premises. Furthermore, the methods cannot be directly applied to existing revision-based corpora from other domains due to limited data and metadata. Additional efforts would be needed to improve the approach's effectiveness.\",\n",
              " 'The autoregressive span selection strategy addresses the limitations of current span-based parsing methods by weakening the imposed conditional independence assumptions. However, it introduces another restrictive bias by forcing a predefined span selection order. While using post-order selection performs decently, it is not necessarily the best option and other potential orders remain unexplored. In addition, the non-deterministic nature of splitting points in discontinuous parsing can be challenging to handle. Moreover, there are two major limitations to the method: inadequate grammar constraints and prediction time. The use of a strong, general grammar and considering complex distributions could potentially improve results. Additionally, the assumption that both source-side and qcfg grammars are in CNF may',\n",
              " \"The privacy-enhancing techniques used in model training have some significant limitations that must be considered. This includes the use of closed-source models, which may not be acceptable in many settings due to the need to send data to third-party APIs. Technical limitations also restrict the effectiveness of these techniques, such as a focus on improving one particular approach and uncertainty about whether it can be applied to others. Additionally, training and implementing large models using differential privacy can be difficult and computationally intensive, rendering it inaccessible to many users. This is due to the need for per-example gradients and large batch sizes, which can limit the model's ability to learn from rare patterns in the training data. While the proposed method for\",\n",
              " 'NLP model comparison is limited in practical applications due to their confinement to artificial datasets, without clear implications on real-world tasks. The results only pertain to text classification and lack inclusion of other NLP problems. The experiments were limited to fixed strings and did not consider a wider range of tasks or task shifts. Environmental concerns and practical limitations prevent the study from including models larger than t5-large, preventing a comparison of emergent properties. Therefore, the findings are primarily applicable to low-resource scenarios and may not be representative of larger models. However, the study does provide valuable insights into the performance of mlp-based architectures in text classification tasks under constrained compute budgets. There is a need for further research',\n",
              " 'The collection of documents on metaphor and figurative language processing covers various aspects, including visual metaphor generation, cross-lingual analysis, and reasoning in text puzzles. While there is potential for human-AI collaboration in visual metaphor generation, the limitations and challenges, such as cultural context and reliance on paid APIs, are also discussed. Additionally, the need for more comprehensive consideration of language and figurative speech, diversity in metaphor generation, and exploration of diverse lexical units is highlighted. These challenges indicate a need for further progress in the field and demonstrate the complexities involved in accurately processing metaphors and figurative language.',\n",
              " 'The proposed uncertainty-aware bootstrap learning framework for joint extraction achieves state-of-the-art performance but requires large training resources due to the ensemble loss and probability variance calculation. The constructed corpus integrates RE with NER and aims to measure the impact of NER on relation extraction through multi-task learning. However, due to limited size, experiments on SSI were not conducted. Advancements in information extraction are limited by the slow inference stage, lack of interaction and heterogeneous embedding spaces, and the need for an extra module in identifying relations. To address these issues, a unified textual entailment framework called TEA is proposed, which transforms relational and attribute triples into textual sequences and models the EA task as a bi-directional',\n",
              " 'The documents address the obstacles and restrictions in instructing AI systems, such as chatgpt, to comprehend and produce humor, including sarcasm and jokes. The difficulties entail the subjective nature of humor, differentiating between legitimate errors and mistakenly assigned significance by automated systems, and the incorporation of multimodal data like text within images. Additionally, the tendency of AI to generate persuasive yet inaccurate explanations is also highlighted. Key areas of focus include the particular challenges of detecting irony and sarcasm in text, reliance on insufficient datasets and pre-trained models, and the examination of humor characteristics in AI-generated material. Overall, limitations lie in the subjective and complex nature of humor, as well as the limitations of current AI',\n",
              " 'This study aims to identify anorexia, self-harm, and depression in social media users using a language model. However, the reliability of the results may be limited as the model and baseline models were trained on social media texts and tested on online text. Therefore, the findings may not accurately reflect real-life clinical settings. The paper also focuses on automatically detecting depressive symptoms from memes on social media, but the sample used may have similar limitations to other datasets focusing on naturalistic behavior related to a specific event.',\n",
              " 'The main idea of promptrank is to use a designed prompt to rank candidates in natural language processing. However, experiments show that a decoder-only model is more suitable for prompts generated by co-prompt. Despite strong results, residual prompt tuning has limitations, as its performance is not as good as fine-tuning and it requires more parameters to train. Additionally, the focus is on tasks with simple instructions, which may pose a greater evaluation challenge. The overall goal is to study instruction induction in lab conditions, which is limited by the simplicity of the tasks. This suggests that the effectiveness of promptrank may vary depending on the complexity of the task.',\n",
              " 'One limitation of the study is that the chosen fairness metrics may not accurately capture all aspects of bias and must be carefully selected for the specific context and task at hand. This highlights the importance of having experts in the field to fully understand and interpret the bias. The use of social bias benchmarks in the study also raises concerns about their underlying assumptions and potential cultural biases. Additionally, the study only focuses on biases present in contemporary English language, potentially overlooking cross-cultural differences in stereotypes. The use of human-collected lists for counterfactual data augmentation and intervened distribution generation may not cover all relevant demographic groups. There is potential for improvement in the model by considering more diverse perspectives and demographic axes.',\n",
              " 'The focus of the documents is on the challenges faced in enhancing efficiency and decreasing computational complexity in Neural Machine Translation (NMT). These challenges include the expensive computational costs of SSMT models due to additional decoding steps, the slower decoding speeds and lower sample efficiency of SSD-LM models compared to AR-LM models, the inability to apply the DEPA approach to different NMT models, and the significant memory and storage requirements of using kNN-MT for faster decoding without addressing other underlying issues. These limitations suggest that further research and development is needed to overcome these obstacles and improve the overall efficiency of NMT models.']"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "turbo_instruct_summaries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_gpt_3_summary = pd.DataFrame(turbo_instruct_summaries, columns=['Text'])\n",
        "df_gpt_3_summary"
      ],
      "metadata": {
        "id": "KOqXbeght8Eh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}